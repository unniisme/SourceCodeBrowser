[
 {
  "docstring": "Compute edge weights and eliminate zero-weight edges.",
  "code": "def _preprocess_graph(G, weight):\n    if G.is_directed():\n        H = nx.MultiGraph()\n        H.add_nodes_from(G)\n        H.add_weighted_edges_from(((u, v, e.get(weight, 1.0)) for u, v, e in G.edges(data=True) if u != v), weight=weight)\n        G = H\n    if not G.is_multigraph():\n        edges = ((u, v, abs(e.get(weight, 1.0))) for u, v, e in G.edges(data=True) if u != v)\n    else:\n        edges = ((u, v, sum((abs(e.get(weight, 1.0)) for e in G[u][v].values()))) for u, v in G.edges() if u != v)\n    H = nx.Graph()\n    H.add_nodes_from(G)\n    H.add_weighted_edges_from(((u, v, e) for u, v, e in edges if e != 0))\n    return H"
 },
 {
  "docstring": "Estimate the Fiedler vector using the reverse Cuthill-McKee ordering.",
  "code": "def _rcm_estimate(G, nodelist):\n    import numpy as np\n    G = G.subgraph(nodelist)\n    order = reverse_cuthill_mckee_ordering(G)\n    n = len(nodelist)\n    index = dict(zip(nodelist, range(n)))\n    x = np.ndarray(n, dtype=float)\n    for i, u in enumerate(order):\n        x[index[u]] = i\n    x -= (n - 1) / 2.0\n    return x"
 },
 {
  "docstring": "Compute the Fiedler vector of L using the TraceMIN-Fiedler algorithm.\n\nThe Fiedler vector of a connected undirected graph is the eigenvector\ncorresponding to the second smallest eigenvalue of the Laplacian matrix\nof the graph. This function starts with the Laplacian L, not the Graph.\n\nParameters\n----------\nL : Laplacian of a possibly weighted or normalized, but undirected graph\n\nX : Initial guess for a solution. Usually a matrix of random numbers.\n    This function allows more than one column in X to identify more than\n    one eigenvector if desired.\n\nnormalized : bool\n    Whether the normalized Laplacian matrix is used.\n\ntol : float\n    Tolerance of relative residual in eigenvalue computation.\n    Warning: There is no limit on number of iterations.\n\nmethod : string\n    Should be 'tracemin_pcg' or 'tracemin_lu'.\n    Otherwise exception is raised.\n\nReturns\n-------\nsigma, X : Two NumPy arrays of floats.\n    The lowest eigenvalues and corresponding eigenvectors of L.\n    The size of input X determines the size of these outputs.\n    As this is for Fiedler vectors, the zero eigenvalue (and\n    constant eigenvector) are avoided.",
  "code": "def _tracemin_fiedler(L, X, normalized, tol, method):\n    import numpy as np\n    import scipy as sp\n    n = X.shape[0]\n    if normalized:\n        e = np.sqrt(L.diagonal())\n        D = sp.sparse.csr_array(sp.sparse.spdiags(1 / e, 0, n, n, format='csr'))\n        L = D @ L @ D\n        e *= 1.0 / np.linalg.norm(e, 2)\n    if normalized:\n\n        def project(X):\n            \"\"\"Make X orthogonal to the nullspace of L.\"\"\"\n            X = np.asarray(X)\n            for j in range(X.shape[1]):\n                X[:, j] -= X[:, j] @ e * e\n    else:\n\n        def project(X):\n            \"\"\"Make X orthogonal to the nullspace of L.\"\"\"\n            X = np.asarray(X)\n            for j in range(X.shape[1]):\n                X[:, j] -= X[:, j].sum() / n\n    if method == 'tracemin_pcg':\n        D = L.diagonal().astype(float)\n        solver = _PCGSolver(lambda x: L @ x, lambda x: D * x)\n    elif method == 'tracemin_lu':\n        A = sp.sparse.csc_array(L, dtype=float, copy=True)\n        i = (A.indptr[1:] - A.indptr[:-1]).argmax()\n        A[i, i] = float('inf')\n        solver = _LUSolver(A)\n    else:\n        raise nx.NetworkXError(f'Unknown linear system solver: {method}')\n    Lnorm = abs(L).sum(axis=1).flatten().max()\n    project(X)\n    W = np.ndarray(X.shape, order='F')\n    while True:\n        X = np.linalg.qr(X)[0]\n        W[:, :] = L @ X\n        H = X.T @ W\n        sigma, Y = sp.linalg.eigh(H, overwrite_a=True)\n        X = X @ Y\n        res = sp.linalg.blas.dasum(W @ Y[:, 0] - sigma[0] * X[:, 0]) / Lnorm\n        if res < tol:\n            break\n        W[:, :] = solver.solve(X, tol)\n        X = (sp.linalg.inv(W.T @ X) @ W.T).T\n        project(X)\n    return (sigma, np.asarray(X))"
 },
 {
  "docstring": "Returns a function that solves the Fiedler eigenvalue problem.",
  "code": "def _get_fiedler_func(method):\n    import numpy as np\n    if method == 'tracemin':\n        method = 'tracemin_pcg'\n    if method in ('tracemin_pcg', 'tracemin_lu'):\n\n        def find_fiedler(L, x, normalized, tol, seed):\n            q = 1 if method == 'tracemin_pcg' else min(4, L.shape[0] - 1)\n            X = np.asarray(seed.normal(size=(q, L.shape[0]))).T\n            sigma, X = _tracemin_fiedler(L, X, normalized, tol, method)\n            return (sigma[0], X[:, 0])\n    elif method == 'lanczos' or method == 'lobpcg':\n\n        def find_fiedler(L, x, normalized, tol, seed):\n            import scipy as sp\n            L = sp.sparse.csc_array(L, dtype=float)\n            n = L.shape[0]\n            if normalized:\n                D = sp.sparse.csc_array(sp.sparse.spdiags(1.0 / np.sqrt(L.diagonal()), [0], n, n, format='csc'))\n                L = D @ L @ D\n            if method == 'lanczos' or n < 10:\n                sigma, X = sp.sparse.linalg.eigsh(L, 2, which='SM', tol=tol, return_eigenvectors=True)\n                return (sigma[1], X[:, 1])\n            else:\n                X = np.asarray(np.atleast_2d(x).T)\n                M = sp.sparse.csr_array(sp.sparse.spdiags(1.0 / L.diagonal(), 0, n, n))\n                Y = np.ones(n)\n                if normalized:\n                    Y /= D.diagonal()\n                sigma, X = sp.sparse.linalg.lobpcg(L, X, M=M, Y=np.atleast_2d(Y).T, tol=tol, maxiter=n, largest=False)\n                return (sigma[0], X[:, 0])\n    else:\n        raise nx.NetworkXError(f'unknown method {method!r}.')\n    return find_fiedler"
 },
 {
  "docstring": "Returns the algebraic connectivity of an undirected graph.\n\nThe algebraic connectivity of a connected undirected graph is the second\nsmallest eigenvalue of its Laplacian matrix.\n\nParameters\n----------\nG : NetworkX graph\n    An undirected graph.\n\nweight : object, optional (default: None)\n    The data key used to determine the weight of each edge. If None, then\n    each edge has unit weight.\n\nnormalized : bool, optional (default: False)\n    Whether the normalized Laplacian matrix is used.\n\ntol : float, optional (default: 1e-8)\n    Tolerance of relative residual in eigenvalue computation.\n\nmethod : string, optional (default: 'tracemin_pcg')\n    Method of eigenvalue computation. It must be one of the tracemin\n    options shown below (TraceMIN), 'lanczos' (Lanczos iteration)\n    or 'lobpcg' (LOBPCG).\n\n    The TraceMIN algorithm uses a linear system solver. The following\n    values allow specifying the solver to be used.\n\n    =============== ========================================\n    Value           Solver\n    =============== ========================================\n    'tracemin_pcg'  Preconditioned conjugate gradient method\n    'tracemin_lu'   LU factorization\n    =============== ========================================\n\nseed : integer, random_state, or None (default)\n    Indicator of random number generation state.\n    See :ref:`Randomness<randomness>`.\n\nReturns\n-------\nalgebraic_connectivity : float\n    Algebraic connectivity.\n\nRaises\n------\nNetworkXNotImplemented\n    If G is directed.\n\nNetworkXError\n    If G has less than two nodes.\n\n",
  "code": "@not_implemented_for('directed')\n@np_random_state(5)\n@nx._dispatch(edge_attrs='weight')\ndef algebraic_connectivity(G, weight='weight', normalized=False, tol=1e-08, method='tracemin_pcg', seed=None):\n    if len(G) < 2:\n        raise nx.NetworkXError('graph has less than two nodes.')\n    G = _preprocess_graph(G, weight)\n    if not nx.is_connected(G):\n        return 0.0\n    L = nx.laplacian_matrix(G)\n    if L.shape[0] == 2:\n        return 2.0 * L[0, 0] if not normalized else 2.0\n    find_fiedler = _get_fiedler_func(method)\n    x = None if method != 'lobpcg' else _rcm_estimate(G, G)\n    sigma, fiedler = find_fiedler(L, x, normalized, tol, seed)\n    return sigma"
 },
 {
  "docstring": "Returns the Fiedler vector of a connected undirected graph.\n\nThe Fiedler vector of a connected undirected graph is the eigenvector\ncorresponding to the second smallest eigenvalue of the Laplacian matrix\nof the graph.\n\nParameters\n----------\nG : NetworkX graph\n    An undirected graph.\n\nweight : object, optional (default: None)\n    The data key used to determine the weight of each edge. If None, then\n    each edge has unit weight.\n\nnormalized : bool, optional (default: False)\n    Whether the normalized Laplacian matrix is used.\n\ntol : float, optional (default: 1e-8)\n    Tolerance of relative residual in eigenvalue computation.\n\nmethod : string, optional (default: 'tracemin_pcg')\n    Method of eigenvalue computation. It must be one of the tracemin\n    options shown below (TraceMIN), 'lanczos' (Lanczos iteration)\n    or 'lobpcg' (LOBPCG).\n\n    The TraceMIN algorithm uses a linear system solver. The following\n    values allow specifying the solver to be used.\n\n    =============== ========================================\n    Value           Solver\n    =============== ========================================\n    'tracemin_pcg'  Preconditioned conjugate gradient method\n    'tracemin_lu'   LU factorization\n    =============== ========================================\n\nseed : integer, random_state, or None (default)\n    Indicator of random number generation state.\n    See :ref:`Randomness<randomness>`.\n\nReturns\n-------\nfiedler_vector : NumPy array of floats.\n    Fiedler vector.\n\nRaises\n------\nNetworkXNotImplemented\n    If G is directed.\n\nNetworkXError\n    If G has less than two nodes or is not connected.\n\n",
  "code": "@not_implemented_for('directed')\n@np_random_state(5)\n@nx._dispatch(edge_attrs='weight')\ndef fiedler_vector(G, weight='weight', normalized=False, tol=1e-08, method='tracemin_pcg', seed=None):\n    import numpy as np\n    if len(G) < 2:\n        raise nx.NetworkXError('graph has less than two nodes.')\n    G = _preprocess_graph(G, weight)\n    if not nx.is_connected(G):\n        raise nx.NetworkXError('graph is not connected.')\n    if len(G) == 2:\n        return np.array([1.0, -1.0])\n    find_fiedler = _get_fiedler_func(method)\n    L = nx.laplacian_matrix(G)\n    x = None if method != 'lobpcg' else _rcm_estimate(G, G)\n    sigma, fiedler = find_fiedler(L, x, normalized, tol, seed)\n    return fiedler"
 },
 {
  "docstring": "Compute the spectral_ordering of a graph.\n\nThe spectral ordering of a graph is an ordering of its nodes where nodes\nin the same weakly connected components appear contiguous and ordered by\ntheir corresponding elements in the Fiedler vector of the component.\n\nParameters\n----------\nG : NetworkX graph\n    A graph.\n\nweight : object, optional (default: None)\n    The data key used to determine the weight of each edge. If None, then\n    each edge has unit weight.\n\nnormalized : bool, optional (default: False)\n    Whether the normalized Laplacian matrix is used.\n\ntol : float, optional (default: 1e-8)\n    Tolerance of relative residual in eigenvalue computation.\n\nmethod : string, optional (default: 'tracemin_pcg')\n    Method of eigenvalue computation. It must be one of the tracemin\n    options shown below (TraceMIN), 'lanczos' (Lanczos iteration)\n    or 'lobpcg' (LOBPCG).\n\n    The TraceMIN algorithm uses a linear system solver. The following\n    values allow specifying the solver to be used.\n\n    =============== ========================================\n    Value           Solver\n    =============== ========================================\n    'tracemin_pcg'  Preconditioned conjugate gradient method\n    'tracemin_lu'   LU factorization\n    =============== ========================================\n\nseed : integer, random_state, or None (default)\n    Indicator of random number generation state.\n    See :ref:`Randomness<randomness>`.\n\nReturns\n-------\nspectral_ordering : NumPy array of floats.\n    Spectral ordering of nodes.\n\nRaises\n------\nNetworkXError\n    If G is empty.\n\n",
  "code": "@np_random_state(5)\n@nx._dispatch(edge_attrs='weight')\ndef spectral_ordering(G, weight='weight', normalized=False, tol=1e-08, method='tracemin_pcg', seed=None):\n    if len(G) == 0:\n        raise nx.NetworkXError('graph is empty.')\n    G = _preprocess_graph(G, weight)\n    find_fiedler = _get_fiedler_func(method)\n    order = []\n    for component in nx.connected_components(G):\n        size = len(component)\n        if size > 2:\n            L = nx.laplacian_matrix(G, component)\n            x = None if method != 'lobpcg' else _rcm_estimate(G, component)\n            sigma, fiedler = find_fiedler(L, x, normalized, tol, seed)\n            sort_info = zip(fiedler, range(size), component)\n            order.extend((u for x, c, u in sorted(sort_info)))\n        else:\n            order.extend(component)\n    return order"
 },
 {
  "docstring": "Bisect the graph using the Fiedler vector.\n\nThis method uses the Fiedler vector to bisect a graph.\nThe partition is defined by the nodes which are associated with\neither positive or negative values in the vector.\n\nParameters\n----------\nG : NetworkX Graph\n\nweight : str, optional (default: weight)\n    The data key used to determine the weight of each edge. If None, then\n    each edge has unit weight.\n\nnormalized : bool, optional (default: False)\n    Whether the normalized Laplacian matrix is used.\n\ntol : float, optional (default: 1e-8)\n    Tolerance of relative residual in eigenvalue computation.\n\nmethod : string, optional (default: 'tracemin_pcg')\n    Method of eigenvalue computation. It must be one of the tracemin\n    options shown below (TraceMIN), 'lanczos' (Lanczos iteration)\n    or 'lobpcg' (LOBPCG).\n\n    The TraceMIN algorithm uses a linear system solver. The following\n    values allow specifying the solver to be used.\n\n    =============== ========================================\n    Value           Solver\n    =============== ========================================\n    'tracemin_pcg'  Preconditioned conjugate gradient method\n    'tracemin_lu'   LU factorization\n    =============== ========================================\n\nseed : integer, random_state, or None (default)\n    Indicator of random number generation state.\n    See :ref:`Randomness<randomness>`.\n\nReturns\n-------\nbisection : tuple of sets\n    Sets with the bisection of nodes\n\nExamples\n--------\n>>> G = nx.barbell_graph(3, 0)\n>>> nx.spectral_bisection(G)\n({0, 1, 2}, {3, 4, 5})\n\n",
  "code": "@nx._dispatch(edge_attrs='weight')\ndef spectral_bisection(G, weight='weight', normalized=False, tol=1e-08, method='tracemin_pcg', seed=None):\n    import numpy as np\n    v = nx.fiedler_vector(G, weight, normalized, tol, method, seed)\n    nodes = np.array(list(G))\n    pos_vals = v >= 0\n    return (set(nodes[~pos_vals]), set(nodes[pos_vals]))"
 },
 {
  "docstring": "Make X orthogonal to the nullspace of L.",
  "code": "def project(X):\n    X = np.asarray(X)\n    for j in range(X.shape[1]):\n        X[:, j] -= X[:, j] @ e * e"
 },
 {
  "docstring": "Make X orthogonal to the nullspace of L.",
  "code": "def project(X):\n    X = np.asarray(X)\n    for j in range(X.shape[1]):\n        X[:, j] -= X[:, j].sum() / n"
 },
 {
  "docstring": "Returns a function that returns a value from G.nodes[u].\n\nWe return a function expecting a node as its sole argument. Then, in the\nsimplest scenario, the returned function will return G.nodes[u][node_attr].\nHowever, we also handle the case when `node_attr` is None or when it is a\nfunction itself.\n\nParameters\n----------\nG : graph\n    A NetworkX graph\n\nnode_attr : {None, str, callable}\n    Specification of how the value of the node attribute should be obtained\n    from the node attribute dictionary.\n\nReturns\n-------\nvalue : function\n    A function expecting a node as its sole argument. The function will\n    returns a value from G.nodes[u] that depends on `edge_attr`.",
  "code": "def _node_value(G, node_attr):\n    if node_attr is None:\n\n        def value(u):\n            return u\n    elif not callable(node_attr):\n\n        def value(u):\n            return G.nodes[u][node_attr]\n    else:\n        value = node_attr\n    return value"
 },
 {
  "docstring": "Returns a function that returns a value from G[u][v].\n\nSuppose there exists an edge between u and v.  Then we return a function\nexpecting u and v as arguments.  For Graph and DiGraph, G[u][v] is\nthe edge attribute dictionary, and the function (essentially) returns\nG[u][v][edge_attr].  However, we also handle cases when `edge_attr` is None\nand when it is a function itself. For MultiGraph and MultiDiGraph, G[u][v]\nis a dictionary of all edges between u and v.  In this case, the returned\nfunction sums the value of `edge_attr` for every edge between u and v.\n\nParameters\n----------\nG : graph\n   A NetworkX graph\n\nedge_attr : {None, str, callable}\n    Specification of how the value of the edge attribute should be obtained\n    from the edge attribute dictionary, G[u][v].  For multigraphs, G[u][v]\n    is a dictionary of all the edges between u and v.  This allows for\n    special treatment of multiedges.\n\nReturns\n-------\nvalue : function\n    A function expecting two nodes as parameters. The nodes should\n    represent the from- and to- node of an edge. The function will\n    return a value from G[u][v] that depends on `edge_attr`.",
  "code": "def _edge_value(G, edge_attr):\n    if edge_attr is None:\n        if G.is_multigraph():\n\n            def value(u, v):\n                return len(G[u][v])\n        else:\n\n            def value(u, v):\n                return 1\n    elif not callable(edge_attr):\n        if edge_attr == 'weight':\n            if G.is_multigraph():\n\n                def value(u, v):\n                    return sum((d.get(edge_attr, 1) for d in G[u][v].values()))\n            else:\n\n                def value(u, v):\n                    return G[u][v].get(edge_attr, 1)\n        elif G.is_multigraph():\n\n            def value(u, v):\n                return sum((d[edge_attr] for d in G[u][v].values()))\n        else:\n\n            def value(u, v):\n                return G[u][v][edge_attr]\n    else:\n        value = edge_attr\n    return value"
 },
 {
  "docstring": "Returns the attribute matrix using attributes from `G` as a numpy array.\n\nIf only `G` is passed in, then the adjacency matrix is constructed.\n\nLet A be a discrete set of values for the node attribute `node_attr`. Then\nthe elements of A represent the rows and columns of the constructed matrix.\nNow, iterate through every edge e=(u,v) in `G` and consider the value\nof the edge attribute `edge_attr`.  If ua and va are the values of the\nnode attribute `node_attr` for u and v, respectively, then the value of\nthe edge attribute is added to the matrix element at (ua, va).\n\nParameters\n----------\nG : graph\n    The NetworkX graph used to construct the attribute matrix.\n\nedge_attr : str, optional\n    Each element of the matrix represents a running total of the\n    specified edge attribute for edges whose node attributes correspond\n    to the rows/cols of the matrix. The attribute must be present for\n    all edges in the graph. If no attribute is specified, then we\n    just count the number of edges whose node attributes correspond\n    to the matrix element.\n\nnode_attr : str, optional\n    Each row and column in the matrix represents a particular value\n    of the node attribute.  The attribute must be present for all nodes\n    in the graph. Note, the values of this attribute should be reliably\n    hashable. So, float values are not recommended. If no attribute is\n    specified, then the rows and columns will be the nodes of the graph.\n\nnormalized : bool, optional\n    If True, then each row is normalized by the summation of its values.\n\nrc_order : list, optional\n    A list of the node attribute values. This list specifies the ordering\n    of rows and columns of the array. If no ordering is provided, then\n    the ordering will be random (and also, a return value).\n\nOther Parameters\n----------------\ndtype : NumPy data-type, optional\n    A valid NumPy dtype used to initialize the array. Keep in mind certain\n    dtypes can yield unexpected results if the array is to be normalized.\n    The parameter is passed to numpy.zeros(). If unspecified, the NumPy\n    default is used.\n\norder : {'C', 'F'}, optional\n    Whether to store multidimensional data in C- or Fortran-contiguous\n    (row- or column-wise) order in memory. This parameter is passed to\n    numpy.zeros(). If unspecified, the NumPy default is used.\n\nReturns\n-------\nM : 2D NumPy ndarray\n    The attribute matrix.\n\nordering : list\n    If `rc_order` was specified, then only the attribute matrix is returned.\n    However, if `rc_order` was None, then the ordering used to construct\n    the matrix is returned as well.\n\nExamples\n--------\nConstruct an adjacency matrix:\n\n>>> G = nx.Graph()\n>>> G.add_edge(0, 1, thickness=1, weight=3)\n>>> G.add_edge(0, 2, thickness=2)\n>>> G.add_edge(1, 2, thickness=3)\n>>> nx.attr_matrix(G, rc_order=[0, 1, 2])\narray([[0., 1., 1.],\n       [1., 0., 1.],\n       [1., 1., 0.]])\n\nAlternatively, we can obtain the matrix describing edge thickness.\n\n>>> nx.attr_matrix(G, edge_attr=\"thickness\", rc_order=[0, 1, 2])\narray([[0., 1., 2.],\n       [1., 0., 3.],\n       [2., 3., 0.]])\n\nWe can also color the nodes and ask for the probability distribution over\nall edges (u,v) describing:\n\n    Pr(v has color Y | u has color X)\n\n>>> G.nodes[0][\"color\"] = \"red\"\n>>> G.nodes[1][\"color\"] = \"red\"\n>>> G.nodes[2][\"color\"] = \"blue\"\n>>> rc = [\"red\", \"blue\"]\n>>> nx.attr_matrix(G, node_attr=\"color\", normalized=True, rc_order=rc)\narray([[0.33333333, 0.66666667],\n       [1.        , 0.        ]])\n\nFor example, the above tells us that for all edges (u,v):\n\n    Pr( v is red  | u is red)  = 1/3\n    Pr( v is blue | u is red)  = 2/3\n\n    Pr( v is red  | u is blue) = 1\n    Pr( v is blue | u is blue) = 0\n\nFinally, we can obtain the total weights listed by the node colors.\n\n>>> nx.attr_matrix(G, edge_attr=\"weight\", node_attr=\"color\", rc_order=rc)\narray([[3., 2.],\n       [2., 0.]])\n\nThus, the total weight over all edges (u,v) with u and v having colors:\n\n    (red, red)   is 3   # the sole contribution is from edge (0,1)\n    (red, blue)  is 2   # contributions from edges (0,2) and (1,2)\n    (blue, red)  is 2   # same as (red, blue) since graph is undirected\n    (blue, blue) is 0   # there are no edges with blue endpoints",
  "code": "@nx._dispatch(edge_attrs={'edge_attr': None}, node_attrs='node_attr')\ndef attr_matrix(G, edge_attr=None, node_attr=None, normalized=False, rc_order=None, dtype=None, order=None):\n    import numpy as np\n    edge_value = _edge_value(G, edge_attr)\n    node_value = _node_value(G, node_attr)\n    if rc_order is None:\n        ordering = list({node_value(n) for n in G})\n    else:\n        ordering = rc_order\n    N = len(ordering)\n    undirected = not G.is_directed()\n    index = dict(zip(ordering, range(N)))\n    M = np.zeros((N, N), dtype=dtype, order=order)\n    seen = set()\n    for u, nbrdict in G.adjacency():\n        for v in nbrdict:\n            i, j = (index[node_value(u)], index[node_value(v)])\n            if v not in seen:\n                M[i, j] += edge_value(u, v)\n                if undirected:\n                    M[j, i] = M[i, j]\n        if undirected:\n            seen.add(u)\n    if normalized:\n        M /= M.sum(axis=1).reshape((N, 1))\n    if rc_order is None:\n        return (M, ordering)\n    else:\n        return M"
 },
 {
  "docstring": "Returns a SciPy sparse array using attributes from G.\n\nIf only `G` is passed in, then the adjacency matrix is constructed.\n\nLet A be a discrete set of values for the node attribute `node_attr`. Then\nthe elements of A represent the rows and columns of the constructed matrix.\nNow, iterate through every edge e=(u,v) in `G` and consider the value\nof the edge attribute `edge_attr`.  If ua and va are the values of the\nnode attribute `node_attr` for u and v, respectively, then the value of\nthe edge attribute is added to the matrix element at (ua, va).\n\nParameters\n----------\nG : graph\n    The NetworkX graph used to construct the NumPy matrix.\n\nedge_attr : str, optional\n    Each element of the matrix represents a running total of the\n    specified edge attribute for edges whose node attributes correspond\n    to the rows/cols of the matrix. The attribute must be present for\n    all edges in the graph. If no attribute is specified, then we\n    just count the number of edges whose node attributes correspond\n    to the matrix element.\n\nnode_attr : str, optional\n    Each row and column in the matrix represents a particular value\n    of the node attribute.  The attribute must be present for all nodes\n    in the graph. Note, the values of this attribute should be reliably\n    hashable. So, float values are not recommended. If no attribute is\n    specified, then the rows and columns will be the nodes of the graph.\n\nnormalized : bool, optional\n    If True, then each row is normalized by the summation of its values.\n\nrc_order : list, optional\n    A list of the node attribute values. This list specifies the ordering\n    of rows and columns of the array. If no ordering is provided, then\n    the ordering will be random (and also, a return value).\n\nOther Parameters\n----------------\ndtype : NumPy data-type, optional\n    A valid NumPy dtype used to initialize the array. Keep in mind certain\n    dtypes can yield unexpected results if the array is to be normalized.\n    The parameter is passed to numpy.zeros(). If unspecified, the NumPy\n    default is used.\n\nReturns\n-------\nM : SciPy sparse array\n    The attribute matrix.\n\nordering : list\n    If `rc_order` was specified, then only the matrix is returned.\n    However, if `rc_order` was None, then the ordering used to construct\n    the matrix is returned as well.\n\nExamples\n--------\nConstruct an adjacency matrix:\n\n>>> G = nx.Graph()\n>>> G.add_edge(0, 1, thickness=1, weight=3)\n>>> G.add_edge(0, 2, thickness=2)\n>>> G.add_edge(1, 2, thickness=3)\n>>> M = nx.attr_sparse_matrix(G, rc_order=[0, 1, 2])\n>>> M.toarray()\narray([[0., 1., 1.],\n       [1., 0., 1.],\n       [1., 1., 0.]])\n\nAlternatively, we can obtain the matrix describing edge thickness.\n\n>>> M = nx.attr_sparse_matrix(G, edge_attr=\"thickness\", rc_order=[0, 1, 2])\n>>> M.toarray()\narray([[0., 1., 2.],\n       [1., 0., 3.],\n       [2., 3., 0.]])\n\nWe can also color the nodes and ask for the probability distribution over\nall edges (u,v) describing:\n\n    Pr(v has color Y | u has color X)\n\n>>> G.nodes[0][\"color\"] = \"red\"\n>>> G.nodes[1][\"color\"] = \"red\"\n>>> G.nodes[2][\"color\"] = \"blue\"\n>>> rc = [\"red\", \"blue\"]\n>>> M = nx.attr_sparse_matrix(G, node_attr=\"color\", normalized=True, rc_order=rc)\n>>> M.toarray()\narray([[0.33333333, 0.66666667],\n       [1.        , 0.        ]])\n\nFor example, the above tells us that for all edges (u,v):\n\n    Pr( v is red  | u is red)  = 1/3\n    Pr( v is blue | u is red)  = 2/3\n\n    Pr( v is red  | u is blue) = 1\n    Pr( v is blue | u is blue) = 0\n\nFinally, we can obtain the total weights listed by the node colors.\n\n>>> M = nx.attr_sparse_matrix(G, edge_attr=\"weight\", node_attr=\"color\", rc_order=rc)\n>>> M.toarray()\narray([[3., 2.],\n       [2., 0.]])\n\nThus, the total weight over all edges (u,v) with u and v having colors:\n\n    (red, red)   is 3   # the sole contribution is from edge (0,1)\n    (red, blue)  is 2   # contributions from edges (0,2) and (1,2)\n    (blue, red)  is 2   # same as (red, blue) since graph is undirected\n    (blue, blue) is 0   # there are no edges with blue endpoints",
  "code": "@nx._dispatch(edge_attrs={'edge_attr': None}, node_attrs='node_attr')\ndef attr_sparse_matrix(G, edge_attr=None, node_attr=None, normalized=False, rc_order=None, dtype=None):\n    import numpy as np\n    import scipy as sp\n    edge_value = _edge_value(G, edge_attr)\n    node_value = _node_value(G, node_attr)\n    if rc_order is None:\n        ordering = list({node_value(n) for n in G})\n    else:\n        ordering = rc_order\n    N = len(ordering)\n    undirected = not G.is_directed()\n    index = dict(zip(ordering, range(N)))\n    M = sp.sparse.lil_array((N, N), dtype=dtype)\n    seen = set()\n    for u, nbrdict in G.adjacency():\n        for v in nbrdict:\n            i, j = (index[node_value(u)], index[node_value(v)])\n            if v not in seen:\n                M[i, j] += edge_value(u, v)\n                if undirected:\n                    M[j, i] = M[i, j]\n        if undirected:\n            seen.add(u)\n    if normalized:\n        M *= 1 / M.sum(axis=1)[:, np.newaxis]\n    if rc_order is None:\n        return (M, ordering)\n    else:\n        return M"
 },
 {
  "docstring": "Returns the Bethe Hessian matrix of G.\n\nThe Bethe Hessian is a family of matrices parametrized by r, defined as\nH(r) = (r^2 - 1) I - r A + D where A is the adjacency matrix, D is the\ndiagonal matrix of node degrees, and I is the identify matrix. It is equal\nto the graph laplacian when the regularizer r = 1.\n\nThe default choice of regularizer should be the ratio [2]_\n\n.. math::\n  r_m = \\left(\\sum k_i \\right)^{-1}\\left(\\sum k_i^2 \\right) - 1\n\nParameters\n----------\nG : Graph\n   A NetworkX graph\nr : float\n   Regularizer parameter\nnodelist : list, optional\n   The rows and columns are ordered according to the nodes in nodelist.\n   If nodelist is None, then the ordering is produced by ``G.nodes()``.\n\nReturns\n-------\nH : scipy.sparse.csr_array\n  The Bethe Hessian matrix of `G`, with parameter `r`.\n\nExamples\n--------\n>>> k = [3, 2, 2, 1, 0]\n>>> G = nx.havel_hakimi_graph(k)\n>>> H = nx.bethe_hessian_matrix(G)\n>>> H.toarray()\narray([[ 3.5625, -1.25  , -1.25  , -1.25  ,  0.    ],\n       [-1.25  ,  2.5625, -1.25  ,  0.    ,  0.    ],\n       [-1.25  , -1.25  ,  2.5625,  0.    ,  0.    ],\n       [-1.25  ,  0.    ,  0.    ,  1.5625,  0.    ],\n       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.5625]])\n\nSee Also\n--------\nbethe_hessian_spectrum\nadjacency_matrix\nlaplacian_matrix\n\n",
  "code": "@not_implemented_for('directed')\n@not_implemented_for('multigraph')\n@nx._dispatch\ndef bethe_hessian_matrix(G, r=None, nodelist=None):\n    import scipy as sp\n    if nodelist is None:\n        nodelist = list(G)\n    if r is None:\n        r = sum((d ** 2 for v, d in nx.degree(G))) / sum((d for v, d in nx.degree(G))) - 1\n    A = nx.to_scipy_sparse_array(G, nodelist=nodelist, format='csr')\n    n, m = A.shape\n    D = sp.sparse.csr_array(sp.sparse.spdiags(A.sum(axis=1), 0, m, n, format='csr'))\n    I = sp.sparse.csr_array(sp.sparse.eye(m, n, format='csr'))\n    return (r ** 2 - 1) * I - r * A + D"
 },
 {
  "docstring": "Returns incidence matrix of G.\n\nThe incidence matrix assigns each row to a node and each column to an edge.\nFor a standard incidence matrix a 1 appears wherever a row's node is\nincident on the column's edge.  For an oriented incidence matrix each\nedge is assigned an orientation (arbitrarily for undirected and aligning to\ndirection for directed).  A -1 appears for the source (tail) of an edge and\n1 for the destination (head) of the edge.  The elements are zero otherwise.\n\nParameters\n----------\nG : graph\n   A NetworkX graph\n\nnodelist : list, optional   (default= all nodes in G)\n   The rows are ordered according to the nodes in nodelist.\n   If nodelist is None, then the ordering is produced by G.nodes().\n\nedgelist : list, optional (default= all edges in G)\n   The columns are ordered according to the edges in edgelist.\n   If edgelist is None, then the ordering is produced by G.edges().\n\noriented: bool, optional (default=False)\n   If True, matrix elements are +1 or -1 for the head or tail node\n   respectively of each edge.  If False, +1 occurs at both nodes.\n\nweight : string or None, optional (default=None)\n   The edge data key used to provide each value in the matrix.\n   If None, then each edge has weight 1.  Edge weights, if used,\n   should be positive so that the orientation can provide the sign.\n\ndtype : a NumPy dtype or None (default=None)\n    The dtype of the output sparse array. This type should be a compatible\n    type of the weight argument, eg. if weight would return a float this\n    argument should also be a float.\n    If None, then the default for SciPy is used.\n\nReturns\n-------\nA : SciPy sparse array\n  The incidence matrix of G.\n\n",
  "code": "@nx._dispatch(edge_attrs='weight')\ndef incidence_matrix(G, nodelist=None, edgelist=None, oriented=False, weight=None, *, dtype=None):\n    import scipy as sp\n    if nodelist is None:\n        nodelist = list(G)\n    if edgelist is None:\n        if G.is_multigraph():\n            edgelist = list(G.edges(keys=True))\n        else:\n            edgelist = list(G.edges())\n    A = sp.sparse.lil_array((len(nodelist), len(edgelist)), dtype=dtype)\n    node_index = {node: i for i, node in enumerate(nodelist)}\n    for ei, e in enumerate(edgelist):\n        u, v = e[:2]\n        if u == v:\n            continue\n        try:\n            ui = node_index[u]\n            vi = node_index[v]\n        except KeyError as err:\n            raise nx.NetworkXError(f'node {u} or {v} in edgelist but not in nodelist') from err\n        if weight is None:\n            wt = 1\n        elif G.is_multigraph():\n            ekey = e[2]\n            wt = G[u][v][ekey].get(weight, 1)\n        else:\n            wt = G[u][v].get(weight, 1)\n        if oriented:\n            A[ui, ei] = -wt\n            A[vi, ei] = wt\n        else:\n            A[ui, ei] = wt\n            A[vi, ei] = wt\n    return A.asformat('csc')"
 },
 {
  "docstring": "Returns adjacency matrix of G.\n\nParameters\n----------\nG : graph\n   A NetworkX graph\n\nnodelist : list, optional\n   The rows and columns are ordered according to the nodes in nodelist.\n   If nodelist is None, then the ordering is produced by G.nodes().\n\ndtype : NumPy data-type, optional\n    The desired data-type for the array.\n    If None, then the NumPy default is used.\n\nweight : string or None, optional (default='weight')\n   The edge data key used to provide each value in the matrix.\n   If None, then each edge has weight 1.\n\nReturns\n-------\nA : SciPy sparse array\n  Adjacency matrix representation of G.\n\n",
  "code": "@nx._dispatch(edge_attrs='weight')\ndef adjacency_matrix(G, nodelist=None, dtype=None, weight='weight'):\n    return nx.to_scipy_sparse_array(G, nodelist=nodelist, dtype=dtype, weight=weight)"
 },
 {
  "docstring": "Returns the Laplacian matrix of G.\n\nThe graph Laplacian is the matrix L = D - A, where\nA is the adjacency matrix and D is the diagonal matrix of node degrees.\n\nParameters\n----------\nG : graph\n   A NetworkX graph\n\nnodelist : list, optional\n   The rows and columns are ordered according to the nodes in nodelist.\n   If nodelist is None, then the ordering is produced by G.nodes().\n\nweight : string or None, optional (default='weight')\n   The edge data key used to compute each value in the matrix.\n   If None, then each edge has weight 1.\n\nReturns\n-------\nL : SciPy sparse array\n  The Laplacian matrix of G.\n\n",
  "code": "@not_implemented_for('directed')\n@nx._dispatch(edge_attrs='weight')\ndef laplacian_matrix(G, nodelist=None, weight='weight'):\n    import scipy as sp\n    if nodelist is None:\n        nodelist = list(G)\n    A = nx.to_scipy_sparse_array(G, nodelist=nodelist, weight=weight, format='csr')\n    n, m = A.shape\n    D = sp.sparse.csr_array(sp.sparse.spdiags(A.sum(axis=1), 0, m, n, format='csr'))\n    return D - A"
 },
 {
  "docstring": "Returns the normalized Laplacian matrix of G.\n\nThe normalized graph Laplacian is the matrix\n\n.. math::\n\n    N = D^{-1/2} L D^{-1/2}\n\nwhere `L` is the graph Laplacian and `D` is the diagonal matrix of\nnode degrees [1]_.\n\nParameters\n----------\nG : graph\n   A NetworkX graph\n\nnodelist : list, optional\n   The rows and columns are ordered according to the nodes in nodelist.\n   If nodelist is None, then the ordering is produced by G.nodes().\n\nweight : string or None, optional (default='weight')\n   The edge data key used to compute each value in the matrix.\n   If None, then each edge has weight 1.\n\nReturns\n-------\nN : SciPy sparse array\n  The normalized Laplacian matrix of G.\n\n",
  "code": "@not_implemented_for('directed')\n@nx._dispatch(edge_attrs='weight')\ndef normalized_laplacian_matrix(G, nodelist=None, weight='weight'):\n    import numpy as np\n    import scipy as sp\n    if nodelist is None:\n        nodelist = list(G)\n    A = nx.to_scipy_sparse_array(G, nodelist=nodelist, weight=weight, format='csr')\n    n, m = A.shape\n    diags = A.sum(axis=1)\n    D = sp.sparse.csr_array(sp.sparse.spdiags(diags, 0, m, n, format='csr'))\n    L = D - A\n    with np.errstate(divide='ignore'):\n        diags_sqrt = 1.0 / np.sqrt(diags)\n    diags_sqrt[np.isinf(diags_sqrt)] = 0\n    DH = sp.sparse.csr_array(sp.sparse.spdiags(diags_sqrt, 0, m, n, format='csr'))\n    return DH @ (L @ DH)"
 },
 {
  "docstring": "Returns the total weight of all spanning trees of `G`.\n\nKirchoff's Tree Matrix Theorem states that the determinant of any cofactor of the\nLaplacian matrix of a graph is the number of spanning trees in the graph. For a\nweighted Laplacian matrix, it is the sum across all spanning trees of the\nmultiplicative weight of each tree. That is, the weight of each tree is the\nproduct of its edge weights.\n\nParameters\n----------\nG : NetworkX Graph\n    The graph to use Kirchhoff's theorem on.\n\nweight : string or None\n    The key for the edge attribute holding the edge weight. If `None`, then\n    each edge is assumed to have a weight of 1 and this function returns the\n    total number of spanning trees in `G`.\n\nReturns\n-------\nfloat\n    The sum of the total multiplicative weights for all spanning trees in `G`",
  "code": "@nx._dispatch(edge_attrs='weight')\ndef total_spanning_tree_weight(G, weight=None):\n    import numpy as np\n    G_laplacian = nx.laplacian_matrix(G, weight=weight).toarray()\n    return abs(np.linalg.det(G_laplacian[1:, 1:]))"
 },
 {
  "docstring": "Returns the directed Laplacian matrix of G.\n\nThe graph directed Laplacian is the matrix\n\n.. math::\n\n    L = I - (\\Phi^{1/2} P \\Phi^{-1/2} + \\Phi^{-1/2} P^T \\Phi^{1/2} ) / 2\n\nwhere `I` is the identity matrix, `P` is the transition matrix of the\ngraph, and `\\Phi` a matrix with the Perron vector of `P` in the diagonal and\nzeros elsewhere [1]_.\n\nDepending on the value of walk_type, `P` can be the transition matrix\ninduced by a random walk, a lazy random walk, or a random walk with\nteleportation (PageRank).\n\nParameters\n----------\nG : DiGraph\n   A NetworkX graph\n\nnodelist : list, optional\n   The rows and columns are ordered according to the nodes in nodelist.\n   If nodelist is None, then the ordering is produced by G.nodes().\n\nweight : string or None, optional (default='weight')\n   The edge data key used to compute each value in the matrix.\n   If None, then each edge has weight 1.\n\nwalk_type : string or None, optional (default=None)\n   If None, `P` is selected depending on the properties of the\n   graph. Otherwise is one of 'random', 'lazy', or 'pagerank'\n\nalpha : real\n   (1 - alpha) is the teleportation probability used with pagerank\n\nReturns\n-------\nL : NumPy matrix\n  Normalized Laplacian of G.\n\n",
  "code": "@not_implemented_for('undirected')\n@not_implemented_for('multigraph')\n@nx._dispatch(edge_attrs='weight')\ndef directed_laplacian_matrix(G, nodelist=None, weight='weight', walk_type=None, alpha=0.95):\n    import numpy as np\n    import scipy as sp\n    P = _transition_matrix(G, nodelist=nodelist, weight=weight, walk_type=walk_type, alpha=alpha)\n    n, m = P.shape\n    evals, evecs = sp.sparse.linalg.eigs(P.T, k=1)\n    v = evecs.flatten().real\n    p = v / v.sum()\n    sqrtp = np.sqrt(np.abs(p))\n    Q = sp.sparse.csr_array(sp.sparse.spdiags(sqrtp, 0, n, n)) @ P @ sp.sparse.csr_array(sp.sparse.spdiags(1.0 / sqrtp, 0, n, n))\n    I = np.identity(len(G))\n    return I - (Q + Q.T) / 2.0"
 },
 {
  "docstring": "Return the directed combinatorial Laplacian matrix of G.\n\nThe graph directed combinatorial Laplacian is the matrix\n\n.. math::\n\n    L = \\Phi - (\\Phi P + P^T \\Phi) / 2\n\nwhere `P` is the transition matrix of the graph and `\\Phi` a matrix\nwith the Perron vector of `P` in the diagonal and zeros elsewhere [1]_.\n\nDepending on the value of walk_type, `P` can be the transition matrix\ninduced by a random walk, a lazy random walk, or a random walk with\nteleportation (PageRank).\n\nParameters\n----------\nG : DiGraph\n   A NetworkX graph\n\nnodelist : list, optional\n   The rows and columns are ordered according to the nodes in nodelist.\n   If nodelist is None, then the ordering is produced by G.nodes().\n\nweight : string or None, optional (default='weight')\n   The edge data key used to compute each value in the matrix.\n   If None, then each edge has weight 1.\n\nwalk_type : string or None, optional (default=None)\n   If None, `P` is selected depending on the properties of the\n   graph. Otherwise is one of 'random', 'lazy', or 'pagerank'\n\nalpha : real\n   (1 - alpha) is the teleportation probability used with pagerank\n\nReturns\n-------\nL : NumPy matrix\n  Combinatorial Laplacian of G.\n\n",
  "code": "@not_implemented_for('undirected')\n@not_implemented_for('multigraph')\n@nx._dispatch(edge_attrs='weight')\ndef directed_combinatorial_laplacian_matrix(G, nodelist=None, weight='weight', walk_type=None, alpha=0.95):\n    import scipy as sp\n    P = _transition_matrix(G, nodelist=nodelist, weight=weight, walk_type=walk_type, alpha=alpha)\n    n, m = P.shape\n    evals, evecs = sp.sparse.linalg.eigs(P.T, k=1)\n    v = evecs.flatten().real\n    p = v / v.sum()\n    Phi = sp.sparse.csr_array(sp.sparse.spdiags(p, 0, n, n)).toarray()\n    return Phi - (Phi @ P + P.T @ Phi) / 2.0"
 },
 {
  "docstring": "Returns the transition matrix of G.\n\nThis is a row stochastic giving the transition probabilities while\nperforming a random walk on the graph. Depending on the value of walk_type,\nP can be the transition matrix induced by a random walk, a lazy random walk,\nor a random walk with teleportation (PageRank).\n\nParameters\n----------\nG : DiGraph\n   A NetworkX graph\n\nnodelist : list, optional\n   The rows and columns are ordered according to the nodes in nodelist.\n   If nodelist is None, then the ordering is produced by G.nodes().\n\nweight : string or None, optional (default='weight')\n   The edge data key used to compute each value in the matrix.\n   If None, then each edge has weight 1.\n\nwalk_type : string or None, optional (default=None)\n   If None, `P` is selected depending on the properties of the\n   graph. Otherwise is one of 'random', 'lazy', or 'pagerank'\n\nalpha : real\n   (1 - alpha) is the teleportation probability used with pagerank\n\nReturns\n-------\nP : numpy.ndarray\n  transition matrix of G.\n\nRaises\n------\nNetworkXError\n    If walk_type not specified or alpha not in valid range",
  "code": "def _transition_matrix(G, nodelist=None, weight='weight', walk_type=None, alpha=0.95):\n    import numpy as np\n    import scipy as sp\n    if walk_type is None:\n        if nx.is_strongly_connected(G):\n            if nx.is_aperiodic(G):\n                walk_type = 'random'\n            else:\n                walk_type = 'lazy'\n        else:\n            walk_type = 'pagerank'\n    A = nx.to_scipy_sparse_array(G, nodelist=nodelist, weight=weight, dtype=float)\n    n, m = A.shape\n    if walk_type in ['random', 'lazy']:\n        DI = sp.sparse.csr_array(sp.sparse.spdiags(1.0 / A.sum(axis=1), 0, n, n))\n        if walk_type == 'random':\n            P = DI @ A\n        else:\n            I = sp.sparse.csr_array(sp.sparse.identity(n))\n            P = (I + DI @ A) / 2.0\n    elif walk_type == 'pagerank':\n        if not 0 < alpha < 1:\n            raise nx.NetworkXError('alpha must be between 0 and 1')\n        A = A.toarray()\n        A[A.sum(axis=1) == 0, :] = 1 / n\n        A = A / A.sum(axis=1)[np.newaxis, :].T\n        P = alpha * A + (1 - alpha) / n\n    else:\n        raise nx.NetworkXError('walk_type must be random, lazy, or pagerank')\n    return P"
 },
 {
  "docstring": "Returns the modularity matrix of G.\n\nThe modularity matrix is the matrix B = A - <A>, where A is the adjacency\nmatrix and <A> is the average adjacency matrix, assuming that the graph\nis described by the configuration model.\n\nMore specifically, the element B_ij of B is defined as\n\n.. math::\n    A_{ij} - {k_i k_j \\over 2 m}\n\nwhere k_i is the degree of node i, and where m is the number of edges\nin the graph. When weight is set to a name of an attribute edge, Aij, k_i,\nk_j and m are computed using its value.\n\nParameters\n----------\nG : Graph\n   A NetworkX graph\n\nnodelist : list, optional\n   The rows and columns are ordered according to the nodes in nodelist.\n   If nodelist is None, then the ordering is produced by G.nodes().\n\nweight : string or None, optional (default=None)\n   The edge attribute that holds the numerical value used for\n   the edge weight.  If None then all edge weights are 1.\n\nReturns\n-------\nB : Numpy array\n  The modularity matrix of G.\n\nExamples\n--------\n>>> k = [3, 2, 2, 1, 0]\n>>> G = nx.havel_hakimi_graph(k)\n>>> B = nx.modularity_matrix(G)\n\n\nSee Also\n--------\nto_numpy_array\nmodularity_spectrum\nadjacency_matrix\ndirected_modularity_matrix\n\n",
  "code": "@not_implemented_for('directed')\n@not_implemented_for('multigraph')\n@nx._dispatch(edge_attrs='weight')\ndef modularity_matrix(G, nodelist=None, weight=None):\n    import numpy as np\n    if nodelist is None:\n        nodelist = list(G)\n    A = nx.to_scipy_sparse_array(G, nodelist=nodelist, weight=weight, format='csr')\n    k = A.sum(axis=1)\n    m = k.sum() * 0.5\n    X = np.outer(k, k) / (2 * m)\n    return A - X"
 },
 {
  "docstring": "Returns the directed modularity matrix of G.\n\nThe modularity matrix is the matrix B = A - <A>, where A is the adjacency\nmatrix and <A> is the expected adjacency matrix, assuming that the graph\nis described by the configuration model.\n\nMore specifically, the element B_ij of B is defined as\n\n.. math::\n    B_{ij} = A_{ij} - k_i^{out} k_j^{in} / m\n\nwhere :math:`k_i^{in}` is the in degree of node i, and :math:`k_j^{out}` is the out degree\nof node j, with m the number of edges in the graph. When weight is set\nto a name of an attribute edge, Aij, k_i, k_j and m are computed using\nits value.\n\nParameters\n----------\nG : DiGraph\n   A NetworkX DiGraph\n\nnodelist : list, optional\n   The rows and columns are ordered according to the nodes in nodelist.\n   If nodelist is None, then the ordering is produced by G.nodes().\n\nweight : string or None, optional (default=None)\n   The edge attribute that holds the numerical value used for\n   the edge weight.  If None then all edge weights are 1.\n\nReturns\n-------\nB : Numpy array\n  The modularity matrix of G.\n\nExamples\n--------\n>>> G = nx.DiGraph()\n>>> G.add_edges_from(\n...     (\n...         (1, 2),\n...         (1, 3),\n...         (3, 1),\n...         (3, 2),\n...         (3, 5),\n...         (4, 5),\n...         (4, 6),\n...         (5, 4),\n...         (5, 6),\n...         (6, 4),\n...     )\n... )\n>>> B = nx.directed_modularity_matrix(G)\n\n\n",
  "code": "@not_implemented_for('undirected')\n@not_implemented_for('multigraph')\n@nx._dispatch(edge_attrs='weight')\ndef directed_modularity_matrix(G, nodelist=None, weight=None):\n    import numpy as np\n    if nodelist is None:\n        nodelist = list(G)\n    A = nx.to_scipy_sparse_array(G, nodelist=nodelist, weight=weight, format='csr')\n    k_in = A.sum(axis=0)\n    k_out = A.sum(axis=1)\n    m = k_in.sum()\n    X = np.outer(k_out, k_in) / m\n    return A - X"
 },
 {
  "docstring": "Returns eigenvalues of the Laplacian of G\n\nParameters\n----------\nG : graph\n   A NetworkX graph\n\nweight : string or None, optional (default='weight')\n   The edge data key used to compute each value in the matrix.\n   If None, then each edge has weight 1.\n\nReturns\n-------\nevals : NumPy array\n  Eigenvalues\n\n",
  "code": "@nx._dispatch(edge_attrs='weight')\ndef laplacian_spectrum(G, weight='weight'):\n    import scipy as sp\n    return sp.linalg.eigvalsh(nx.laplacian_matrix(G, weight=weight).todense())"
 },
 {
  "docstring": "Return eigenvalues of the normalized Laplacian of G\n\nParameters\n----------\nG : graph\n   A NetworkX graph\n\nweight : string or None, optional (default='weight')\n   The edge data key used to compute each value in the matrix.\n   If None, then each edge has weight 1.\n\nReturns\n-------\nevals : NumPy array\n  Eigenvalues\n\n",
  "code": "@nx._dispatch(edge_attrs='weight')\ndef normalized_laplacian_spectrum(G, weight='weight'):\n    import scipy as sp\n    return sp.linalg.eigvalsh(nx.normalized_laplacian_matrix(G, weight=weight).todense())"
 },
 {
  "docstring": "Returns eigenvalues of the adjacency matrix of G.\n\nParameters\n----------\nG : graph\n   A NetworkX graph\n\nweight : string or None, optional (default='weight')\n   The edge data key used to compute each value in the matrix.\n   If None, then each edge has weight 1.\n\nReturns\n-------\nevals : NumPy array\n  Eigenvalues\n\n",
  "code": "@nx._dispatch(edge_attrs='weight')\ndef adjacency_spectrum(G, weight='weight'):\n    import scipy as sp\n    return sp.linalg.eigvals(nx.adjacency_matrix(G, weight=weight).todense())"
 },
 {
  "docstring": "Returns eigenvalues of the modularity matrix of G.\n\nParameters\n----------\nG : Graph\n   A NetworkX Graph or DiGraph\n\nReturns\n-------\nevals : NumPy array\n  Eigenvalues\n\nSee Also\n--------\nmodularity_matrix\n\n",
  "code": "@nx._dispatch\ndef modularity_spectrum(G):\n    import scipy as sp\n    if G.is_directed():\n        return sp.linalg.eigvals(nx.directed_modularity_matrix(G))\n    else:\n        return sp.linalg.eigvals(nx.modularity_matrix(G))"
 },
 {
  "docstring": "Returns eigenvalues of the Bethe Hessian matrix of G.\n\nParameters\n----------\nG : Graph\n   A NetworkX Graph or DiGraph\n\nr : float\n   Regularizer parameter\n\nReturns\n-------\nevals : NumPy array\n  Eigenvalues\n\nSee Also\n--------\nbethe_hessian_matrix\n\n",
  "code": "@nx._dispatch\ndef bethe_hessian_spectrum(G, r=None):\n    import scipy as sp\n    return sp.linalg.eigvalsh(nx.bethe_hessian_matrix(G, r).todense())"
 },
 {
  "docstring": "Test that \"tracemin_chol\" raises an exception.",
  "code": "def test_algebraic_connectivity_tracemin_chol():\n    pytest.importorskip('scipy')\n    G = nx.barbell_graph(5, 4)\n    with pytest.raises(nx.NetworkXError):\n        nx.algebraic_connectivity(G, method='tracemin_chol')"
 },
 {
  "docstring": "Test that \"tracemin_chol\" raises an exception.",
  "code": "def test_fiedler_vector_tracemin_chol():\n    pytest.importorskip('scipy')\n    G = nx.barbell_graph(5, 4)\n    with pytest.raises(nx.NetworkXError):\n        nx.fiedler_vector(G, method='tracemin_chol')"
 },
 {
  "docstring": "Test that \"tracemin_chol\" raises an exception.",
  "code": "def test_spectral_ordering_tracemin_chol():\n    pytest.importorskip('scipy')\n    G = nx.barbell_graph(5, 4)\n    with pytest.raises(nx.NetworkXError):\n        nx.spectral_ordering(G, method='tracemin_chol')"
 },
 {
  "docstring": "Test that \"tracemin_unknown\" raises an exception.",
  "code": "def test_fiedler_vector_tracemin_unknown():\n    pytest.importorskip('scipy')\n    G = nx.barbell_graph(5, 4)\n    L = nx.laplacian_matrix(G)\n    X = np.asarray(np.random.normal(size=(1, L.shape[0]))).T\n    with pytest.raises(nx.NetworkXError, match='Unknown linear system solver'):\n        nx.linalg.algebraicconnectivity._tracemin_fiedler(L, X, normalized=False, tol=1e-08, method='tracemin_unknown')"
 },
 {
  "docstring": "Bethe Hessian matrix",
  "code": "def test_bethe_hessian(self):\n    H = np.array([[4, -2, 0], [-2, 5, -2], [0, -2, 4]])\n    permutation = [2, 0, 1]\n    np.testing.assert_equal(nx.bethe_hessian_matrix(self.P, r=2).todense(), H)\n    np.testing.assert_equal(nx.bethe_hessian_matrix(self.P, r=2, nodelist=permutation).todense(), H[np.ix_(permutation, permutation)])\n    np.testing.assert_equal(nx.bethe_hessian_matrix(self.G, r=1).todense(), nx.laplacian_matrix(self.G).todense())\n    np.testing.assert_equal(nx.bethe_hessian_matrix(self.G).todense(), nx.bethe_hessian_matrix(self.G, r=1.25).todense())"
 },
 {
  "docstring": "Conversion to incidence matrix",
  "code": "def test_incidence_matrix(self):\n    I = nx.incidence_matrix(self.G, nodelist=sorted(self.G), edgelist=sorted(self.G.edges()), oriented=True, dtype=int).todense()\n    np.testing.assert_equal(I, self.OI)\n    I = nx.incidence_matrix(self.G, nodelist=sorted(self.G), edgelist=sorted(self.G.edges()), oriented=False, dtype=int).todense()\n    np.testing.assert_equal(I, np.abs(self.OI))\n    I = nx.incidence_matrix(self.MG, nodelist=sorted(self.MG), edgelist=sorted(self.MG.edges()), oriented=True, dtype=int).todense()\n    np.testing.assert_equal(I, self.OI)\n    I = nx.incidence_matrix(self.MG, nodelist=sorted(self.MG), edgelist=sorted(self.MG.edges()), oriented=False, dtype=int).todense()\n    np.testing.assert_equal(I, np.abs(self.OI))\n    I = nx.incidence_matrix(self.MG2, nodelist=sorted(self.MG2), edgelist=sorted(self.MG2.edges()), oriented=True, dtype=int).todense()\n    np.testing.assert_equal(I, self.MGOI)\n    I = nx.incidence_matrix(self.MG2, nodelist=sorted(self.MG), edgelist=sorted(self.MG2.edges()), oriented=False, dtype=int).todense()\n    np.testing.assert_equal(I, np.abs(self.MGOI))\n    I = nx.incidence_matrix(self.G, dtype=np.uint8)\n    assert I.dtype == np.uint8"
 },
 {
  "docstring": "Conversion to adjacency matrix",
  "code": "def test_adjacency_matrix(self):\n    np.testing.assert_equal(nx.adjacency_matrix(self.G).todense(), self.A)\n    np.testing.assert_equal(nx.adjacency_matrix(self.MG).todense(), self.A)\n    np.testing.assert_equal(nx.adjacency_matrix(self.MG2).todense(), self.MG2A)\n    np.testing.assert_equal(nx.adjacency_matrix(self.G, nodelist=[0, 1]).todense(), self.A[:2, :2])\n    np.testing.assert_equal(nx.adjacency_matrix(self.WG).todense(), self.WA)\n    np.testing.assert_equal(nx.adjacency_matrix(self.WG, weight=None).todense(), self.A)\n    np.testing.assert_equal(nx.adjacency_matrix(self.MG2, weight=None).todense(), self.MG2A)\n    np.testing.assert_equal(nx.adjacency_matrix(self.WG, weight='other').todense(), 0.6 * self.WA)\n    np.testing.assert_equal(nx.adjacency_matrix(self.no_edges_G, nodelist=[1, 3]).todense(), self.no_edges_A)"
 },
 {
  "docstring": "Directed Laplacian",
  "code": "def test_directed_laplacian():\n    G = nx.DiGraph()\n    G.add_edges_from(((1, 2), (1, 3), (3, 1), (3, 2), (3, 5), (4, 5), (4, 6), (5, 4), (5, 6), (6, 4)))\n    GL = np.array([[0.9833, -0.2941, -0.3882, -0.0291, -0.0231, -0.0261], [-0.2941, 0.8333, -0.2339, -0.0536, -0.0589, -0.0554], [-0.3882, -0.2339, 0.9833, -0.0278, -0.0896, -0.0251], [-0.0291, -0.0536, -0.0278, 0.9833, -0.4878, -0.6675], [-0.0231, -0.0589, -0.0896, -0.4878, 0.9833, -0.2078], [-0.0261, -0.0554, -0.0251, -0.6675, -0.2078, 0.9833]])\n    L = nx.directed_laplacian_matrix(G, alpha=0.9, nodelist=sorted(G))\n    np.testing.assert_almost_equal(L, GL, decimal=3)\n    G.add_edges_from(((2, 5), (6, 1)))\n    GL = np.array([[1.0, -0.3062, -0.4714, 0.0, 0.0, -0.3227], [-0.3062, 1.0, -0.1443, 0.0, -0.3162, 0.0], [-0.4714, -0.1443, 1.0, 0.0, -0.0913, 0.0], [0.0, 0.0, 0.0, 1.0, -0.5, -0.5], [0.0, -0.3162, -0.0913, -0.5, 1.0, -0.25], [-0.3227, 0.0, 0.0, -0.5, -0.25, 1.0]])\n    L = nx.directed_laplacian_matrix(G, alpha=0.9, nodelist=sorted(G), walk_type='random')\n    np.testing.assert_almost_equal(L, GL, decimal=3)\n    GL = np.array([[0.5, -0.1531, -0.2357, 0.0, 0.0, -0.1614], [-0.1531, 0.5, -0.0722, 0.0, -0.1581, 0.0], [-0.2357, -0.0722, 0.5, 0.0, -0.0456, 0.0], [0.0, 0.0, 0.0, 0.5, -0.25, -0.25], [0.0, -0.1581, -0.0456, -0.25, 0.5, -0.125], [-0.1614, 0.0, 0.0, -0.25, -0.125, 0.5]])\n    L = nx.directed_laplacian_matrix(G, alpha=0.9, nodelist=sorted(G), walk_type='lazy')\n    np.testing.assert_almost_equal(L, GL, decimal=3)\n    G = nx.DiGraph()\n    G.add_edges_from(((1, 2), (2, 4), (4, 1), (1, 3), (3, 4)))\n    GL = np.array([[0.5, -0.176, -0.176, -0.25], [-0.176, 0.5, 0.0, -0.176], [-0.176, 0.0, 0.5, -0.176], [-0.25, -0.176, -0.176, 0.5]])\n    L = nx.directed_laplacian_matrix(G, alpha=0.9, nodelist=sorted(G))\n    np.testing.assert_almost_equal(L, GL, decimal=3)"
 },
 {
  "docstring": "Directed combinatorial Laplacian",
  "code": "def test_directed_combinatorial_laplacian():\n    G = nx.DiGraph()\n    G.add_edges_from(((1, 2), (1, 3), (3, 1), (3, 2), (3, 5), (4, 5), (4, 6), (5, 4), (5, 6), (6, 4)))\n    GL = np.array([[0.0366, -0.0132, -0.0153, -0.0034, -0.002, -0.0027], [-0.0132, 0.045, -0.0111, -0.0076, -0.0062, -0.0069], [-0.0153, -0.0111, 0.0408, -0.0035, -0.0083, -0.0027], [-0.0034, -0.0076, -0.0035, 0.3688, -0.1356, -0.2187], [-0.002, -0.0062, -0.0083, -0.1356, 0.2026, -0.0505], [-0.0027, -0.0069, -0.0027, -0.2187, -0.0505, 0.2815]])\n    L = nx.directed_combinatorial_laplacian_matrix(G, alpha=0.9, nodelist=sorted(G))\n    np.testing.assert_almost_equal(L, GL, decimal=3)\n    G.add_edges_from(((2, 5), (6, 1)))\n    GL = np.array([[0.1395, -0.0349, -0.0465, 0.0, 0.0, -0.0581], [-0.0349, 0.093, -0.0116, 0.0, -0.0465, 0.0], [-0.0465, -0.0116, 0.0698, 0.0, -0.0116, 0.0], [0.0, 0.0, 0.0, 0.2326, -0.1163, -0.1163], [0.0, -0.0465, -0.0116, -0.1163, 0.2326, -0.0581], [-0.0581, 0.0, 0.0, -0.1163, -0.0581, 0.2326]])\n    L = nx.directed_combinatorial_laplacian_matrix(G, alpha=0.9, nodelist=sorted(G), walk_type='random')\n    np.testing.assert_almost_equal(L, GL, decimal=3)\n    GL = np.array([[0.0698, -0.0174, -0.0233, 0.0, 0.0, -0.0291], [-0.0174, 0.0465, -0.0058, 0.0, -0.0233, 0.0], [-0.0233, -0.0058, 0.0349, 0.0, -0.0058, 0.0], [0.0, 0.0, 0.0, 0.1163, -0.0581, -0.0581], [0.0, -0.0233, -0.0058, -0.0581, 0.1163, -0.0291], [-0.0291, 0.0, 0.0, -0.0581, -0.0291, 0.1163]])\n    L = nx.directed_combinatorial_laplacian_matrix(G, alpha=0.9, nodelist=sorted(G), walk_type='lazy')\n    np.testing.assert_almost_equal(L, GL, decimal=3)\n    E = nx.DiGraph(margulis_gabber_galil_graph(2))\n    L = nx.directed_combinatorial_laplacian_matrix(E)\n    expected = np.array([[0.16666667, -0.08333333, -0.08333333, 0.0], [-0.08333333, 0.16666667, 0.0, -0.08333333], [-0.08333333, 0.0, 0.16666667, -0.08333333], [0.0, -0.08333333, -0.08333333, 0.16666667]])\n    np.testing.assert_almost_equal(L, expected, decimal=6)\n    with pytest.raises(nx.NetworkXError):\n        nx.directed_combinatorial_laplacian_matrix(G, walk_type='pagerank', alpha=100)\n    with pytest.raises(nx.NetworkXError):\n        nx.directed_combinatorial_laplacian_matrix(G, walk_type='silly')"
 },
 {
  "docstring": "Graph Laplacian",
  "code": "def test_laplacian(self):\n    NL = np.array([[3, -1, -1, -1, 0], [-1, 2, -1, 0, 0], [-1, -1, 2, 0, 0], [-1, 0, 0, 1, 0], [0, 0, 0, 0, 0]])\n    WL = 0.5 * NL\n    OL = 0.3 * NL\n    np.testing.assert_equal(nx.laplacian_matrix(self.G).todense(), NL)\n    np.testing.assert_equal(nx.laplacian_matrix(self.MG).todense(), NL)\n    np.testing.assert_equal(nx.laplacian_matrix(self.G, nodelist=[0, 1]).todense(), np.array([[1, -1], [-1, 1]]))\n    np.testing.assert_equal(nx.laplacian_matrix(self.WG).todense(), WL)\n    np.testing.assert_equal(nx.laplacian_matrix(self.WG, weight=None).todense(), NL)\n    np.testing.assert_equal(nx.laplacian_matrix(self.WG, weight='other').todense(), OL)"
 },
 {
  "docstring": "Generalized Graph Laplacian",
  "code": "def test_normalized_laplacian(self):\n    G = np.array([[1.0, -0.408, -0.408, -0.577, 0.0], [-0.408, 1.0, -0.5, 0.0, 0.0], [-0.408, -0.5, 1.0, 0.0, 0.0], [-0.577, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0]])\n    GL = np.array([[1.0, -0.408, -0.408, -0.577, 0.0], [-0.408, 1.0, -0.5, 0.0, 0.0], [-0.408, -0.5, 1.0, 0.0, 0.0], [-0.577, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0]])\n    Lsl = np.array([[0.75, -0.2887, -0.2887, -0.3536, 0.0], [-0.2887, 0.6667, -0.3333, 0.0, 0.0], [-0.2887, -0.3333, 0.6667, 0.0, 0.0], [-0.3536, 0.0, 0.0, 0.5, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0]])\n    np.testing.assert_almost_equal(nx.normalized_laplacian_matrix(self.G, nodelist=range(5)).todense(), G, decimal=3)\n    np.testing.assert_almost_equal(nx.normalized_laplacian_matrix(self.G).todense(), GL, decimal=3)\n    np.testing.assert_almost_equal(nx.normalized_laplacian_matrix(self.MG).todense(), GL, decimal=3)\n    np.testing.assert_almost_equal(nx.normalized_laplacian_matrix(self.WG).todense(), GL, decimal=3)\n    np.testing.assert_almost_equal(nx.normalized_laplacian_matrix(self.WG, weight='other').todense(), GL, decimal=3)\n    np.testing.assert_almost_equal(nx.normalized_laplacian_matrix(self.Gsl).todense(), Lsl, decimal=3)"
 },
 {
  "docstring": "Modularity matrix",
  "code": "def test_modularity(self):\n    B = np.array([[-1.125, 0.25, 0.25, 0.625, 0.0], [0.25, -0.5, 0.5, -0.25, 0.0], [0.25, 0.5, -0.5, -0.25, 0.0], [0.625, -0.25, -0.25, -0.125, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0]])\n    permutation = [4, 0, 1, 2, 3]\n    np.testing.assert_equal(nx.modularity_matrix(self.G), B)\n    np.testing.assert_equal(nx.modularity_matrix(self.G, nodelist=permutation), B[np.ix_(permutation, permutation)])"
 },
 {
  "docstring": "Modularity matrix with weights",
  "code": "def test_modularity_weight(self):\n    B = np.array([[-1.125, 0.25, 0.25, 0.625, 0.0], [0.25, -0.5, 0.5, -0.25, 0.0], [0.25, 0.5, -0.5, -0.25, 0.0], [0.625, -0.25, -0.25, -0.125, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0]])\n    G_weighted = self.G.copy()\n    for n1, n2 in G_weighted.edges():\n        G_weighted.edges[n1, n2]['weight'] = 0.5\n    np.testing.assert_equal(nx.modularity_matrix(G_weighted), B)\n    np.testing.assert_equal(nx.modularity_matrix(G_weighted, weight='weight'), 0.5 * B)"
 },
 {
  "docstring": "Directed Modularity matrix",
  "code": "def test_directed_modularity(self):\n    B = np.array([[-0.2, 0.6, 0.8, -0.4, -0.4, -0.4], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7, 0.4, -0.3, -0.6, 0.4, -0.6], [-0.2, -0.4, -0.2, -0.4, 0.6, 0.6], [-0.2, -0.4, -0.2, 0.6, -0.4, 0.6], [-0.1, -0.2, -0.1, 0.8, -0.2, -0.2]])\n    node_permutation = [5, 1, 2, 3, 4, 6]\n    idx_permutation = [4, 0, 1, 2, 3, 5]\n    mm = nx.directed_modularity_matrix(self.DG, nodelist=sorted(self.DG))\n    np.testing.assert_equal(mm, B)\n    np.testing.assert_equal(nx.directed_modularity_matrix(self.DG, nodelist=node_permutation), B[np.ix_(idx_permutation, idx_permutation)])"
 },
 {
  "docstring": "Laplacian eigenvalues",
  "code": "def test_laplacian_spectrum(self):\n    evals = np.array([0, 0, 1, 3, 4])\n    e = sorted(nx.laplacian_spectrum(self.G))\n    np.testing.assert_almost_equal(e, evals)\n    e = sorted(nx.laplacian_spectrum(self.WG, weight=None))\n    np.testing.assert_almost_equal(e, evals)\n    e = sorted(nx.laplacian_spectrum(self.WG))\n    np.testing.assert_almost_equal(e, 0.5 * evals)\n    e = sorted(nx.laplacian_spectrum(self.WG, weight='other'))\n    np.testing.assert_almost_equal(e, 0.3 * evals)"
 },
 {
  "docstring": "Normalized Laplacian eigenvalues",
  "code": "def test_normalized_laplacian_spectrum(self):\n    evals = np.array([0, 0, 0.7712864461218, 1.5, 1.7287135538781])\n    e = sorted(nx.normalized_laplacian_spectrum(self.G))\n    np.testing.assert_almost_equal(e, evals)\n    e = sorted(nx.normalized_laplacian_spectrum(self.WG, weight=None))\n    np.testing.assert_almost_equal(e, evals)\n    e = sorted(nx.normalized_laplacian_spectrum(self.WG))\n    np.testing.assert_almost_equal(e, evals)\n    e = sorted(nx.normalized_laplacian_spectrum(self.WG, weight='other'))\n    np.testing.assert_almost_equal(e, evals)"
 },
 {
  "docstring": "Adjacency eigenvalues",
  "code": "def test_adjacency_spectrum(self):\n    evals = np.array([-np.sqrt(2), 0, np.sqrt(2)])\n    e = sorted(nx.adjacency_spectrum(self.P))\n    np.testing.assert_almost_equal(e, evals)"
 },
 {
  "docstring": "Modularity eigenvalues",
  "code": "def test_modularity_spectrum(self):\n    evals = np.array([-1.5, 0.0, 0.0])\n    e = sorted(nx.modularity_spectrum(self.P))\n    np.testing.assert_almost_equal(e, evals)\n    evals = np.array([-0.5, 0.0, 0.0])\n    e = sorted(nx.modularity_spectrum(self.DG))\n    np.testing.assert_almost_equal(e, evals)"
 },
 {
  "docstring": "Bethe Hessian eigenvalues",
  "code": "def test_bethe_hessian_spectrum(self):\n    evals = np.array([0.5 * (9 - np.sqrt(33)), 4, 0.5 * (9 + np.sqrt(33))])\n    e = sorted(nx.bethe_hessian_spectrum(self.P, r=2))\n    np.testing.assert_almost_equal(e, evals)\n    e1 = sorted(nx.bethe_hessian_spectrum(self.P, r=1))\n    e2 = sorted(nx.laplacian_spectrum(self.P))\n    np.testing.assert_almost_equal(e1, e2)"
 }
]