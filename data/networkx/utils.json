[
 {
  "docstring": "Can the specified backend run this algorithms with these arguments?",
  "code": "def _can_backend_run(self, backend_name, /, *args, **kwargs):\n    backend = _load_backend(backend_name)\n    return hasattr(backend, self.name) and (not hasattr(backend, 'can_run') or backend.can_run(self.name, args, kwargs))"
 },
 {
  "docstring": "Convert graph arguments to the specified backend.\n\nReturns\n-------\nargs tuple and kwargs dict",
  "code": "def _convert_arguments(self, backend_name, args, kwargs):\n    bound = self.__signature__.bind(*args, **kwargs)\n    bound.apply_defaults()\n    if not self.graphs:\n        bound_kwargs = bound.kwargs\n        del bound_kwargs['backend']\n        return (bound.args, bound_kwargs)\n    preserve_edge_attrs = self.preserve_edge_attrs\n    edge_attrs = self.edge_attrs\n    if preserve_edge_attrs is False:\n        pass\n    elif preserve_edge_attrs is True:\n        edge_attrs = None\n    elif isinstance(preserve_edge_attrs, str):\n        if bound.arguments[preserve_edge_attrs] is True or callable(bound.arguments[preserve_edge_attrs]):\n            preserve_edge_attrs = True\n            edge_attrs = None\n        elif bound.arguments[preserve_edge_attrs] is False and (isinstance(edge_attrs, str) and edge_attrs == preserve_edge_attrs or (isinstance(edge_attrs, dict) and preserve_edge_attrs in edge_attrs)):\n            preserve_edge_attrs = False\n            edge_attrs = None\n        else:\n            preserve_edge_attrs = False\n    if edge_attrs is None:\n        pass\n    elif isinstance(edge_attrs, str):\n        if edge_attrs[0] == '[':\n            edge_attrs = {edge_attr: 1 for edge_attr in bound.arguments[edge_attrs[1:-1]]}\n        elif callable(bound.arguments[edge_attrs]):\n            preserve_edge_attrs = True\n            edge_attrs = None\n        elif bound.arguments[edge_attrs] is not None:\n            edge_attrs = {bound.arguments[edge_attrs]: 1}\n        elif self.name == 'to_numpy_array' and hasattr(bound.arguments['dtype'], 'names'):\n            edge_attrs = {edge_attr: 1 for edge_attr in bound.arguments['dtype'].names}\n        else:\n            edge_attrs = None\n    else:\n        edge_attrs = {edge_attr: bound.arguments.get(val, 1) if isinstance(val, str) else val for key, val in edge_attrs.items() if (edge_attr := bound.arguments[key]) is not None}\n    preserve_node_attrs = self.preserve_node_attrs\n    node_attrs = self.node_attrs\n    if preserve_node_attrs is False:\n        pass\n    elif preserve_node_attrs is True:\n        node_attrs = None\n    elif isinstance(preserve_node_attrs, str):\n        if bound.arguments[preserve_node_attrs] is True or callable(bound.arguments[preserve_node_attrs]):\n            preserve_node_attrs = True\n            node_attrs = None\n        elif bound.arguments[preserve_node_attrs] is False and (isinstance(node_attrs, str) and node_attrs == preserve_node_attrs or (isinstance(node_attrs, dict) and preserve_node_attrs in node_attrs)):\n            preserve_node_attrs = False\n            node_attrs = None\n        else:\n            preserve_node_attrs = False\n    if node_attrs is None:\n        pass\n    elif isinstance(node_attrs, str):\n        if node_attrs[0] == '[':\n            node_attrs = {node_attr: None for node_attr in bound.arguments[node_attrs[1:-1]]}\n        elif callable(bound.arguments[node_attrs]):\n            preserve_node_attrs = True\n            node_attrs = None\n        elif bound.arguments[node_attrs] is not None:\n            node_attrs = {bound.arguments[node_attrs]: None}\n        else:\n            node_attrs = None\n    else:\n        node_attrs = {node_attr: bound.arguments.get(val) if isinstance(val, str) else val for key, val in node_attrs.items() if (node_attr := bound.arguments[key]) is not None}\n    preserve_graph_attrs = self.preserve_graph_attrs\n    backend = _load_backend(backend_name)\n    for gname in self.graphs:\n        if gname in self.list_graphs:\n            bound.arguments[gname] = [backend.convert_from_nx(g, edge_attrs=edge_attrs, node_attrs=node_attrs, preserve_edge_attrs=preserve_edge_attrs, preserve_node_attrs=preserve_node_attrs, preserve_graph_attrs=preserve_graph_attrs, name=self.name, graph_name=gname) if getattr(g, '__networkx_backend__', getattr(g, '__networkx_plugin__', 'networkx')) == 'networkx' else g for g in bound.arguments[gname]]\n        else:\n            graph = bound.arguments[gname]\n            if graph is None:\n                if gname in self.optional_graphs:\n                    continue\n                raise TypeError(f'Missing required graph argument `{gname}` in {self.name} function')\n            if isinstance(preserve_edge_attrs, dict):\n                preserve_edges = False\n                edges = preserve_edge_attrs.get(gname, edge_attrs)\n            else:\n                preserve_edges = preserve_edge_attrs\n                edges = edge_attrs\n            if isinstance(preserve_node_attrs, dict):\n                preserve_nodes = False\n                nodes = preserve_node_attrs.get(gname, node_attrs)\n            else:\n                preserve_nodes = preserve_node_attrs\n                nodes = node_attrs\n            if isinstance(preserve_graph_attrs, set):\n                preserve_graph = gname in preserve_graph_attrs\n            else:\n                preserve_graph = preserve_graph_attrs\n            if getattr(graph, '__networkx_backend__', getattr(graph, '__networkx_plugin__', 'networkx')) == 'networkx':\n                bound.arguments[gname] = backend.convert_from_nx(graph, edge_attrs=edges, node_attrs=nodes, preserve_edge_attrs=preserve_edges, preserve_node_attrs=preserve_nodes, preserve_graph_attrs=preserve_graph, name=self.name, graph_name=gname)\n    bound_kwargs = bound.kwargs\n    del bound_kwargs['backend']\n    return (bound.args, bound_kwargs)"
 },
 {
  "docstring": "Call this dispatchable function with a backend, converting graphs if necessary.",
  "code": "def _convert_and_call(self, backend_name, args, kwargs, *, fallback_to_nx=False):\n    backend = _load_backend(backend_name)\n    if not self._can_backend_run(backend_name, *args, **kwargs):\n        if fallback_to_nx:\n            return self.orig_func(*args, **kwargs)\n        msg = f\"'{self.name}' not implemented by {backend_name}\"\n        if hasattr(backend, self.name):\n            msg += ' with the given arguments'\n        raise RuntimeError(msg)\n    try:\n        converted_args, converted_kwargs = self._convert_arguments(backend_name, args, kwargs)\n        result = getattr(backend, self.name)(*converted_args, **converted_kwargs)\n    except (NotImplementedError, NetworkXNotImplemented) as exc:\n        if fallback_to_nx:\n            return self.orig_func(*args, **kwargs)\n        raise\n    return result"
 },
 {
  "docstring": "Call this dispatchable function with a backend; for use with testing.",
  "code": "def _convert_and_call_for_tests(self, backend_name, args, kwargs, *, fallback_to_nx=False):\n    backend = _load_backend(backend_name)\n    if not self._can_backend_run(backend_name, *args, **kwargs):\n        if fallback_to_nx or not self.graphs:\n            return self.orig_func(*args, **kwargs)\n        import pytest\n        msg = f\"'{self.name}' not implemented by {backend_name}\"\n        if hasattr(backend, self.name):\n            msg += ' with the given arguments'\n        pytest.xfail(msg)\n    from collections.abc import Iterator\n    from copy import copy\n    from io import BufferedReader, BytesIO\n    from itertools import tee\n    from random import Random\n    if not args:\n        args1 = args2 = args\n    else:\n        args1, args2 = zip(*((arg, copy(arg)) if isinstance(arg, Random | BytesIO) else tee(arg) if isinstance(arg, Iterator) and (not isinstance(arg, BufferedReader)) else (arg, arg) for arg in args))\n    if not kwargs:\n        kwargs1 = kwargs2 = kwargs\n    else:\n        kwargs1, kwargs2 = zip(*(((k, v), (k, copy(v))) if isinstance(v, Random | BytesIO) else ((k, (teed := tee(v))[0]), (k, teed[1])) if isinstance(v, Iterator) and (not isinstance(v, BufferedReader)) else ((k, v), (k, v)) for k, v in kwargs.items()))\n        kwargs1 = dict(kwargs1)\n        kwargs2 = dict(kwargs2)\n    try:\n        converted_args, converted_kwargs = self._convert_arguments(backend_name, args1, kwargs1)\n        result = getattr(backend, self.name)(*converted_args, **converted_kwargs)\n    except (NotImplementedError, NetworkXNotImplemented) as exc:\n        if fallback_to_nx:\n            return self.orig_func(*args2, **kwargs2)\n        import pytest\n        pytest.xfail(exc.args[0] if exc.args else f'{self.name} raised {type(exc).__name__}')\n    if self.name in {'edmonds_karp_core', 'barycenter', 'contracted_edge', 'contracted_nodes', 'stochastic_graph', 'relabel_nodes'}:\n        bound = self.__signature__.bind(*converted_args, **converted_kwargs)\n        bound.apply_defaults()\n        bound2 = self.__signature__.bind(*args2, **kwargs2)\n        bound2.apply_defaults()\n        if self.name == 'edmonds_karp_core':\n            R1 = backend.convert_to_nx(bound.arguments['R'])\n            R2 = bound2.arguments['R']\n            for k, v in R1.edges.items():\n                R2.edges[k]['flow'] = v['flow']\n        elif self.name == 'barycenter' and bound.arguments['attr'] is not None:\n            G1 = backend.convert_to_nx(bound.arguments['G'])\n            G2 = bound2.arguments['G']\n            attr = bound.arguments['attr']\n            for k, v in G1.nodes.items():\n                G2.nodes[k][attr] = v[attr]\n        elif self.name in {'contracted_nodes', 'contracted_edge'} and (not bound.arguments['copy']):\n            G1 = backend.convert_to_nx(bound.arguments['G'])\n            G2 = bound2.arguments['G']\n            G2.__dict__.update(G1.__dict__)\n        elif self.name == 'stochastic_graph' and (not bound.arguments['copy']):\n            G1 = backend.convert_to_nx(bound.arguments['G'])\n            G2 = bound2.arguments['G']\n            for k, v in G1.edges.items():\n                G2.edges[k]['weight'] = v['weight']\n        elif self.name == 'relabel_nodes' and (not bound.arguments['copy']):\n            G1 = backend.convert_to_nx(bound.arguments['G'])\n            G2 = bound2.arguments['G']\n            if G1 is G2:\n                return G2\n            G2._node.clear()\n            G2._node.update(G1._node)\n            G2._adj.clear()\n            G2._adj.update(G1._adj)\n            if hasattr(G1, '_pred') and hasattr(G2, '_pred'):\n                G2._pred.clear()\n                G2._pred.update(G1._pred)\n            if hasattr(G1, '_succ') and hasattr(G2, '_succ'):\n                G2._succ.clear()\n                G2._succ.update(G1._succ)\n            return G2\n        return backend.convert_to_nx(result)\n    converted_result = backend.convert_to_nx(result)\n    if isinstance(converted_result, nx.Graph) and self.name not in {'boykov_kolmogorov', 'preflow_push', 'quotient_graph', 'shortest_augmenting_path', 'spectral_graph_forge', 'read_gml', 'read_graph6', 'read_sparse6', 'bipartite_read_edgelist', 'read_adjlist', 'read_edgelist', 'read_graphml', 'read_multiline_adjlist', 'read_pajek', 'read_gexf'}:\n        G = self.orig_func(*args2, **kwargs2)\n        if not nx.utils.graphs_equal(G, converted_result):\n            assert G.number_of_nodes() == converted_result.number_of_nodes()\n            assert G.number_of_edges() == converted_result.number_of_edges()\n            assert G.graph == converted_result.graph\n            assert G.nodes == converted_result.nodes\n            assert G.adj == converted_result.adj\n            assert type(G) is type(converted_result)\n            raise AssertionError('Graphs are not equal')\n        return G\n    return converted_result"
 },
 {
  "docstring": "Allow this object to be serialized with pickle.\n\nThis uses the global registry `_registered_algorithms` to deserialize.",
  "code": "def __reduce__(self):\n    return (_restore_dispatch, (self.name,))"
 },
 {
  "docstring": "Decorator to mark algorithms as not implemented\n\nParameters\n----------\ngraph_types : container of strings\n    Entries must be one of \"directed\", \"undirected\", \"multigraph\", or \"graph\".\n\nReturns\n-------\n_require : function\n    The decorated function.\n\nRaises\n------\nNetworkXNotImplemented\nIf any of the packages cannot be imported\n\n",
  "code": "def not_implemented_for(*graph_types):\n    if 'directed' in graph_types and 'undirected' in graph_types:\n        raise ValueError('Function not implemented on directed AND undirected graphs?')\n    if 'multigraph' in graph_types and 'graph' in graph_types:\n        raise ValueError('Function not implemented on graph AND multigraphs?')\n    if not set(graph_types) < {'directed', 'undirected', 'multigraph', 'graph'}:\n        raise KeyError(f'use one or more of directed, undirected, multigraph, graph.  You used {graph_types}')\n    dval = 'directed' in graph_types or ('undirected' not in graph_types and None)\n    mval = 'multigraph' in graph_types or ('graph' not in graph_types and None)\n    errmsg = f'not implemented for {' '.join(graph_types)} type'\n\n    def _not_implemented_for(g):\n        if (mval is None or mval == g.is_multigraph()) and (dval is None or dval == g.is_directed()):\n            raise nx.NetworkXNotImplemented(errmsg)\n        return g\n    return argmap(_not_implemented_for, 0)"
 },
 {
  "docstring": "Decorator to ensure clean opening and closing of files.\n\nParameters\n----------\npath_arg : string or int\n    Name or index of the argument that is a path.\n\nmode : str\n    String for opening mode.\n\nReturns\n-------\n_open_file : function\n    Function which cleanly executes the io.\n\nExamples\n--------\nDecorate functions like this::\n\n   @open_file(0,\"r\")\n   def read_function(pathname):\n       pass\n\n   @open_file(1,\"w\")\n   def write_function(G, pathname):\n       pass\n\n   @open_file(1,\"w\")\n   def write_function(G, pathname=\"graph.dot\"):\n       pass\n\n   @open_file(\"pathname\",\"w\")\n   def write_function(G, pathname=\"graph.dot\"):\n       pass\n\n   @open_file(\"path\", \"w+\")\n   def another_function(arg, **kwargs):\n       path = kwargs[\"path\"]\n       pass\n\n",
  "code": "def open_file(path_arg, mode='r'):\n\n    def _open_file(path):\n        if isinstance(path, str):\n            ext = splitext(path)[1]\n        elif isinstance(path, Path):\n            ext = path.suffix\n            path = str(path)\n        else:\n            return (path, lambda: None)\n        fobj = _dispatch_dict[ext](path, mode=mode)\n        return (fobj, lambda: fobj.close())\n    return argmap(_open_file, path_arg, try_finally=True)"
 },
 {
  "docstring": "Decorator to allow number of nodes or container of nodes.\n\nWith this decorator, the specified argument can be either a number or a container\nof nodes. If it is a number, the nodes used are `range(n)`.\nThis allows `nx.complete_graph(50)` in place of `nx.complete_graph(list(range(50)))`.\nAnd it also allows `nx.complete_graph(any_list_of_nodes)`.\n\nParameters\n----------\nwhich_args : string or int or sequence of strings or ints\n    If string, the name of the argument to be treated.\n    If int, the index of the argument to be treated.\n    If more than one node argument is allowed, can be a list of locations.\n\nReturns\n-------\n_nodes_or_numbers : function\n    Function which replaces int args with ranges.\n\nExamples\n--------\nDecorate functions like this::\n\n   @nodes_or_number(\"nodes\")\n   def empty_graph(nodes):\n       # nodes is converted to a list of nodes\n\n   @nodes_or_number(0)\n   def empty_graph(nodes):\n       # nodes is converted to a list of nodes\n\n   @nodes_or_number([\"m1\", \"m2\"])\n   def grid_2d_graph(m1, m2, periodic=False):\n       # m1 and m2 are each converted to a list of nodes\n\n   @nodes_or_number([0, 1])\n   def grid_2d_graph(m1, m2, periodic=False):\n       # m1 and m2 are each converted to a list of nodes\n\n   @nodes_or_number(1)\n   def full_rary_tree(r, n)\n       # presumably r is a number. It is not handled by this decorator.\n       # n is converted to a list of nodes",
  "code": "def nodes_or_number(which_args):\n\n    def _nodes_or_number(n):\n        try:\n            nodes = list(range(n))\n        except TypeError:\n            nodes = tuple(n)\n        else:\n            if n < 0:\n                raise nx.NetworkXError(f'Negative number of nodes not valid: {n}')\n        return (n, nodes)\n    try:\n        iter_wa = iter(which_args)\n    except TypeError:\n        iter_wa = (which_args,)\n    return argmap(_nodes_or_number, *iter_wa)"
 },
 {
  "docstring": "Decorator to generate a `numpy.random.RandomState` instance.\n\nThe decorator processes the argument indicated by `random_state_argument`\nusing :func:`nx.utils.create_random_state`.\nThe argument value can be a seed (integer), or a `numpy.random.RandomState`\ninstance or (`None` or `numpy.random`). The latter options use the glocal\nrandom number generator used by `numpy.random`.\nThe result is a `numpy.random.RandomState` instance.\n\nParameters\n----------\nrandom_state_argument : string or int\n    The name or index of the argument to be converted\n    to a `numpy.random.RandomState` instance.\n\nReturns\n-------\n_random_state : function\n    Function whose random_state keyword argument is a RandomState instance.\n\nExamples\n--------\nDecorate functions like this::\n\n   @np_random_state(\"seed\")\n   def random_float(seed=None):\n       return seed.rand()\n\n   @np_random_state(0)\n   def random_float(rng=None):\n       return rng.rand()\n\n   @np_random_state(1)\n   def random_array(dims, random_state=1):\n       return random_state.rand(*dims)\n\nSee Also\n--------\npy_random_state",
  "code": "def np_random_state(random_state_argument):\n    return argmap(create_random_state, random_state_argument)"
 },
 {
  "docstring": "Decorator to generate a random.Random instance (or equiv).\n\nThe decorator processes the argument indicated by `random_state_argument`\nusing :func:`nx.utils.create_py_random_state`.\nThe argument value can be a seed (integer), or a random number generator::\n\n    If int, return a random.Random instance set with seed=int.\n    If random.Random instance, return it.\n    If None or the `random` package, return the global random number\n    generator used by `random`.\n    If np.random package, return the global numpy random number\n    generator wrapped in a PythonRandomInterface class.\n    If np.random.RandomState instance, return it wrapped in\n    PythonRandomInterface\n    If a PythonRandomInterface instance, return it\n\nParameters\n----------\nrandom_state_argument : string or int\n    The name of the argument or the index of the argument in args that is\n    to be converted to the random.Random instance or numpy.random.RandomState\n    instance that mimics basic methods of random.Random.\n\nReturns\n-------\n_random_state : function\n    Function whose random_state_argument is converted to a Random instance.\n\nExamples\n--------\nDecorate functions like this::\n\n   @py_random_state(\"random_state\")\n   def random_float(random_state=None):\n       return random_state.rand()\n\n   @py_random_state(0)\n   def random_float(rng=None):\n       return rng.rand()\n\n   @py_random_state(1)\n   def random_array(dims, seed=12345):\n       return seed.rand(*dims)\n\nSee Also\n--------\nnp_random_state",
  "code": "def py_random_state(random_state_argument):\n    return argmap(create_py_random_state, random_state_argument)"
 },
 {
  "docstring": "Decorator for methods that issues warnings for positional arguments.\n\nUsing the keyword-only argument syntax in pep 3102, arguments after the\n* will issue a warning when passed as a positional argument.\n\nParameters\n----------\nfunc : callable, default=None\n    Function to check arguments on.\nversion : callable, default=\"1.3\"\n    The version when positional arguments will result in error.",
  "code": "def deprecate_positional_args(func=None, *, version):\n\n    def _inner_deprecate_positional_args(f):\n        sig = signature(f)\n        kwonly_args = []\n        all_args = []\n        for name, param in sig.parameters.items():\n            if param.kind == Parameter.POSITIONAL_OR_KEYWORD:\n                all_args.append(name)\n            elif param.kind == Parameter.KEYWORD_ONLY:\n                kwonly_args.append(name)\n\n        @wraps(f)\n        def inner_f(*args, **kwargs):\n            extra_args = len(args) - len(all_args)\n            if extra_args <= 0:\n                return f(*args, **kwargs)\n            args_msg = [f'{name}={arg}' for name, arg in zip(kwonly_args[:extra_args], args[-extra_args:])]\n            args_msg = ', '.join(args_msg)\n            warnings.warn(f'Pass {args_msg} as keyword args. From NetworkX version {version} passing these as positional arguments will result in an error', FutureWarning)\n            kwargs.update(zip(sig.parameters, args))\n            return f(**kwargs)\n        return inner_f\n    if func is not None:\n        return _inner_deprecate_positional_args(func)\n    return _inner_deprecate_positional_args"
 },
 {
  "docstring": "Compile the source of a wrapped function\n\nAssemble and compile the decorated function, and intrusively replace its\ncode with the compiled version's.  The thinly wrapped function becomes\nthe decorated function.\n\nParameters\n----------\nfunc : callable\n    A function returned by argmap.__call__ which is in the process\n    of being called for the first time.\n\nReturns\n-------\nfunc : callable\n    The same function, with a new __code__ object.\n\n",
  "code": "@staticmethod\ndef _lazy_compile(func):\n    real_func = func.__argmap__.compile(func.__wrapped__)\n    func.__code__ = real_func.__code__\n    func.__globals__.update(real_func.__globals__)\n    func.__dict__.update(real_func.__dict__)\n    return func"
 },
 {
  "docstring": "Construct a lazily decorated wrapper of f.\n\nThe decorated function will be compiled when it is called for the first time,\nand it will replace its own __code__ object so subsequent calls are fast.\n\nParameters\n----------\nf : callable\n    A function to be decorated.\n\nReturns\n-------\nfunc : callable\n    The decorated function.\n\nSee Also\n--------\nargmap._lazy_compile",
  "code": "def __call__(self, f):\n\n    def func(*args, __wrapper=None, **kwargs):\n        return argmap._lazy_compile(__wrapper)(*args, **kwargs)\n    func.__name__ = f.__name__\n    func.__doc__ = f.__doc__\n    func.__defaults__ = f.__defaults__\n    func.__kwdefaults__.update(f.__kwdefaults__ or {})\n    func.__module__ = f.__module__\n    func.__qualname__ = f.__qualname__\n    func.__dict__.update(f.__dict__)\n    func.__wrapped__ = f\n    func.__kwdefaults__['_argmap__wrapper'] = func\n    func.__self__ = func\n    func.__argmap__ = self\n    if hasattr(f, '__argmap__'):\n        func.__is_generator = f.__is_generator\n    else:\n        func.__is_generator = inspect.isgeneratorfunction(f)\n    if self._finally and func.__is_generator:\n        raise nx.NetworkXError('argmap cannot decorate generators with try_finally')\n    return func"
 },
 {
  "docstring": "Maintain a globally-unique identifier for function names and \"file\" names\n\nNote that this counter is a class method reporting a class variable\nso the count is unique within a Python session. It could differ from\nsession to session for a specific decorator depending on the order\nthat the decorators are created. But that doesn't disrupt `argmap`.\n\nThis is used in two places: to construct unique variable names\nin the `_name` method and to construct unique fictitious filenames\nin the `_compile` method.\n\nReturns\n-------\ncount : int\n    An integer unique to this Python session (simply counts from zero)",
  "code": "@classmethod\ndef _count(cls):\n    cls.__count += 1\n    return cls.__count"
 },
 {
  "docstring": "Mangle the name of a function to be unique but somewhat human-readable\n\nThe names are unique within a Python session and set using `_count`.\n\nParameters\n----------\nf : str or object\n\nReturns\n-------\nname : str\n    The mangled version of `f.__name__` (if `f.__name__` exists) or `f`",
  "code": "@classmethod\ndef _name(cls, f):\n    f = f.__name__ if hasattr(f, '__name__') else f\n    fname = re.sub(cls._bad_chars, '_', f)\n    return f'argmap_{fname}_{cls._count()}'"
 },
 {
  "docstring": "Compile the decorated function.\n\nCalled once for a given decorated function -- collects the code from all\nargmap decorators in the stack, and compiles the decorated function.\n\nMuch of the work done here uses the `assemble` method to allow recursive\ntreatment of multiple argmap decorators on a single decorated function.\nThat flattens the argmap decorators, collects the source code to construct\na single decorated function, then compiles/executes/returns that function.\n\nThe source code for the decorated function is stored as an attribute\n`_code` on the function object itself.\n\nNote that Python's `compile` function requires a filename, but this\ncode is constructed without a file, so a fictitious filename is used\nto describe where the function comes from. The name is something like:\n\"argmap compilation 4\".\n\nParameters\n----------\nf : callable\n    The function to be decorated\n\nReturns\n-------\nfunc : callable\n    The decorated file",
  "code": "def compile(self, f):\n    sig, wrapped_name, functions, mapblock, finallys, mutable_args = self.assemble(f)\n    call = f'{sig.call_sig.format(wrapped_name)}#'\n    mut_args = f'{sig.args} = list({sig.args})' if mutable_args else ''\n    body = argmap._indent(sig.def_sig, mut_args, mapblock, call, finallys)\n    code = '\\n'.join(body)\n    locl = {}\n    globl = dict(functions.values())\n    filename = f'{self.__class__} compilation {self._count()}'\n    compiled = compile(code, filename, 'exec')\n    exec(compiled, globl, locl)\n    func = locl[sig.name]\n    func._code = code\n    return func"
 },
 {
  "docstring": "Collects components of the source for the decorated function wrapping f.\n\nIf `f` has multiple argmap decorators, we recursively assemble the stack of\ndecorators into a single flattened function.\n\nThis method is part of the `compile` method's process yet separated\nfrom that method to allow recursive processing. The outputs are\nstrings, dictionaries and lists that collect needed info to\nflatten any nested argmap-decoration.\n\nParameters\n----------\nf : callable\n    The function to be decorated.  If f is argmapped, we assemble it.\n\nReturns\n-------\nsig : argmap.Signature\n    The function signature as an `argmap.Signature` object.\nwrapped_name : str\n    The mangled name used to represent the wrapped function in the code\n    being assembled.\nfunctions : dict\n    A dictionary mapping id(g) -> (mangled_name(g), g) for functions g\n    referred to in the code being assembled. These need to be present\n    in the ``globals`` scope of ``exec`` when defining the decorated\n    function.\nmapblock : list of lists and/or strings\n    Code that implements mapping of parameters including any try blocks\n    if needed. This code will precede the decorated function call.\nfinallys : list of lists and/or strings\n    Code that implements the finally blocks to post-process the\n    arguments (usually close any files if needed) after the\n    decorated function is called.\nmutable_args : bool\n    True if the decorator needs to modify positional arguments\n    via their indices. The compile method then turns the argument\n    tuple into a list so that the arguments can be modified.",
  "code": "def assemble(self, f):\n    if hasattr(f, '__argmap__') and f.__self__ is f:\n        sig, wrapped_name, functions, mapblock, finallys, mutable_args = f.__argmap__.assemble(f.__wrapped__)\n        functions = dict(functions)\n    else:\n        sig = self.signature(f)\n        wrapped_name = self._name(f)\n        mapblock, finallys = ([], [])\n        functions = {id(f): (wrapped_name, f)}\n        mutable_args = False\n    if id(self._func) in functions:\n        fname, _ = functions[id(self._func)]\n    else:\n        fname, _ = functions[id(self._func)] = (self._name(self._func), self._func)\n    applied = set()\n\n    def get_name(arg, first=True):\n        nonlocal mutable_args\n        if isinstance(arg, tuple):\n            name = ', '.join((get_name(x, False) for x in arg))\n            return name if first else f'({name})'\n        if arg in applied:\n            raise nx.NetworkXError(f'argument {arg} is specified multiple times')\n        applied.add(arg)\n        if arg in sig.names:\n            return sig.names[arg]\n        elif isinstance(arg, str):\n            if sig.kwargs is None:\n                raise nx.NetworkXError(f\"name {arg} is not a named parameter and this function doesn't have kwargs\")\n            return f'{sig.kwargs}[{arg!r}]'\n        else:\n            if sig.args is None:\n                raise nx.NetworkXError(f\"index {arg} not a parameter index and this function doesn't have args\")\n            mutable_args = True\n            return f'{sig.args}[{arg - sig.n_positional}]'\n    if self._finally:\n        for a in self._args:\n            name = get_name(a)\n            final = self._name(name)\n            mapblock.append(f'{name}, {final} = {fname}({name})')\n            mapblock.append('try:')\n            finallys = ['finally:', f'{final}()#', '#', finallys]\n    else:\n        mapblock.extend((f'{name} = {fname}({name})' for name in map(get_name, self._args)))\n    return (sig, wrapped_name, functions, mapblock, finallys, mutable_args)"
 },
 {
  "docstring": "Construct a Signature object describing `f`\n\nCompute a Signature so that we can write a function wrapping f with\nthe same signature and call-type.\n\nParameters\n----------\nf : callable\n    A function to be decorated\n\nReturns\n-------\nsig : argmap.Signature\n    The Signature of f\n\n",
  "code": "@classmethod\ndef signature(cls, f):\n    sig = inspect.signature(f, follow_wrapped=False)\n    def_sig = []\n    call_sig = []\n    names = {}\n    kind = None\n    args = None\n    kwargs = None\n    npos = 0\n    for i, param in enumerate(sig.parameters.values()):\n        prev = kind\n        kind = param.kind\n        if prev == param.POSITIONAL_ONLY != kind:\n            def_sig.append('/')\n        if prev != param.KEYWORD_ONLY == kind != param.VAR_POSITIONAL:\n            def_sig.append('*')\n        if kind == param.VAR_POSITIONAL:\n            name = '*' + param.name\n            args = param.name\n            count = 0\n        elif kind == param.VAR_KEYWORD:\n            name = '**' + param.name\n            kwargs = param.name\n            count = 0\n        else:\n            names[i] = names[param.name] = param.name\n            name = param.name\n            count = 1\n        if kind == param.KEYWORD_ONLY:\n            call_sig.append(f'{name} = {name}')\n        else:\n            npos += count\n            call_sig.append(name)\n        def_sig.append(name)\n    fname = cls._name(f)\n    def_sig = f'def {fname}({', '.join(def_sig)}):'\n    call_sig = f'return {{}}({', '.join(call_sig)})'\n    return cls.Signature(fname, sig, def_sig, call_sig, names, npos, args, kwargs)"
 },
 {
  "docstring": "flattens a recursive list of lists that doesn't have cyclic references\n\nParameters\n----------\nnestlist : iterable\n    A recursive list of objects to be flattened into a single iterable\n\nvisited : set\n    A set of object ids which have been walked -- initialize with an\n    empty set\n\nYields\n------\nNon-list objects contained in nestlist",
  "code": "@staticmethod\ndef _flatten(nestlist, visited):\n    for thing in nestlist:\n        if isinstance(thing, list):\n            if id(thing) in visited:\n                raise ValueError('A cycle was found in nestlist.  Be a tree.')\n            else:\n                visited.add(id(thing))\n            yield from argmap._flatten(thing, visited)\n        else:\n            yield thing"
 },
 {
  "docstring": "Indent list of code lines to make executable Python code\n\nIndents a tree-recursive list of strings, following the rule that one\nspace is added to the tab after a line that ends in a colon, and one is\nremoved after a line that ends in an hashmark.\n\nParameters\n----------\n*lines : lists and/or strings\n    A recursive list of strings to be assembled into properly indented\n    code.\n\nReturns\n-------\ncode : str\n\nExamples\n--------\n\n    argmap._indent(*[\"try:\", \"try:\", \"pass#\", \"finally:\", \"pass#\", \"#\",\n                     \"finally:\", \"pass#\"])\n\nrenders to\n\n    '''try:\n     try:\n      pass#\n     finally:\n      pass#\n     #\n    finally:\n     pass#'''",
  "code": "@staticmethod\ndef _indent(*lines):\n    depth = 0\n    for line in argmap._flatten(lines, set()):\n        yield f'{argmap._tabs[:depth]}{line}'\n        depth += (line[-1:] == ':') - (line[-1:] == '#')"
 },
 {
  "docstring": "Initialize a new min-heap.",
  "code": "def __init__(self):\n    self._dict = {}"
 },
 {
  "docstring": "Query the minimum key-value pair.\n\nReturns\n-------\nkey, value : tuple\n    The key-value pair with the minimum value in the heap.\n\nRaises\n------\nNetworkXError\n    If the heap is empty.",
  "code": "def min(self):\n    raise NotImplementedError"
 },
 {
  "docstring": "Delete the minimum pair in the heap.\n\nReturns\n-------\nkey, value : tuple\n    The key-value pair with the minimum value in the heap.\n\nRaises\n------\nNetworkXError\n    If the heap is empty.",
  "code": "def pop(self):\n    raise NotImplementedError"
 },
 {
  "docstring": "Returns the value associated with a key.\n\nParameters\n----------\nkey : hashable object\n    The key to be looked up.\n\ndefault : object\n    Default value to return if the key is not present in the heap.\n    Default value: None.\n\nReturns\n-------\nvalue : object.\n    The value associated with the key.",
  "code": "def get(self, key, default=None):\n    raise NotImplementedError"
 },
 {
  "docstring": "Insert a new key-value pair or modify the value in an existing\npair.\n\nParameters\n----------\nkey : hashable object\n    The key.\n\nvalue : object comparable with existing values.\n    The value.\n\nallow_increase : bool\n    Whether the value is allowed to increase. If False, attempts to\n    increase an existing value have no effect. Default value: False.\n\nReturns\n-------\ndecreased : bool\n    True if a pair is inserted or the existing value is decreased.",
  "code": "def insert(self, key, value, allow_increase=False):\n    raise NotImplementedError"
 },
 {
  "docstring": "Returns whether the heap if empty.",
  "code": "def __nonzero__(self):\n    return bool(self._dict)"
 },
 {
  "docstring": "Returns whether the heap if empty.",
  "code": "def __bool__(self):\n    return bool(self._dict)"
 },
 {
  "docstring": "Returns the number of key-value pairs in the heap.",
  "code": "def __len__(self):\n    return len(self._dict)"
 },
 {
  "docstring": "Returns whether a key exists in the heap.\n\nParameters\n----------\nkey : any hashable object.\n    The key to be looked up.",
  "code": "def __contains__(self, key):\n    return key in self._dict"
 },
 {
  "docstring": "Initialize a pairing heap.",
  "code": "def __init__(self):\n    super().__init__()\n    self._root = None"
 },
 {
  "docstring": "Link two nodes, making the one with the smaller value the parent of\nthe other.",
  "code": "def _link(self, root, other):\n    if other.value < root.value:\n        root, other = (other, root)\n    next = root.left\n    other.next = next\n    if next is not None:\n        next.prev = other\n    other.prev = None\n    root.left = other\n    other.parent = root\n    return root"
 },
 {
  "docstring": "Merge the subtrees of the root using the standard two-pass method.\nThe resulting subtree is detached from the root.",
  "code": "def _merge_children(self, root):\n    node = root.left\n    root.left = None\n    if node is not None:\n        link = self._link\n        prev = None\n        while True:\n            next = node.next\n            if next is None:\n                node.prev = prev\n                break\n            next_next = next.next\n            node = link(node, next)\n            node.prev = prev\n            prev = node\n            if next_next is None:\n                break\n            node = next_next\n        prev = node.prev\n        while prev is not None:\n            prev_prev = prev.prev\n            node = link(prev, node)\n            prev = prev_prev\n        node.prev = None\n        node.next = None\n        node.parent = None\n    return node"
 },
 {
  "docstring": "Cut a node from its parent.",
  "code": "def _cut(self, node):\n    prev = node.prev\n    next = node.next\n    if prev is not None:\n        prev.next = next\n    else:\n        node.parent.left = next\n    node.prev = None\n    if next is not None:\n        next.prev = prev\n        node.next = None\n    node.parent = None"
 },
 {
  "docstring": "Initialize a binary heap.",
  "code": "def __init__(self):\n    super().__init__()\n    self._heap = []\n    self._count = count()"
 },
 {
  "docstring": "Priority queue class with updatable priorities.",
  "code": "def __init__(self, data=None):\n    if data is None:\n        self.heap = []\n    elif isinstance(data, dict):\n        self.heap = [_HeapElement(v, k) for k, v in data.items()]\n    else:\n        self.heap = list(data)\n    self.position = {}\n    self._heapify()"
 },
 {
  "docstring": "Restore heap invariant and recalculate map.",
  "code": "def _heapify(self):\n    heapq.heapify(self.heap)\n    self.position = {elt: pos for pos, elt in enumerate(self.heap)}\n    if len(self.heap) != len(self.position):\n        raise AssertionError('Heap contains duplicate elements')"
 },
 {
  "docstring": "Add an element to the queue.",
  "code": "def push(self, elt, priority=None):\n    if priority is not None:\n        elt = _HeapElement(priority, elt)\n    if elt in self.position:\n        return False\n    pos = len(self.heap)\n    self.heap.append(elt)\n    self.position[elt] = pos\n    self._siftdown(0, pos)\n    return True"
 },
 {
  "docstring": "Remove and return the smallest element in the queue.",
  "code": "def pop(self):\n    elt = self.heap[0]\n    del self.position[elt]\n    if len(self.heap) == 1:\n        self.heap.pop()\n        return elt\n    last = self.heap.pop()\n    self.heap[0] = last\n    self.position[last] = 0\n    self._siftup(0)\n    return elt"
 },
 {
  "docstring": "Replace an element in the queue with a new one.",
  "code": "def update(self, elt, new, priority=None):\n    if priority is not None:\n        new = _HeapElement(priority, new)\n    pos = self.position[elt]\n    self.heap[pos] = new\n    del self.position[elt]\n    self.position[new] = pos\n    self._siftup(pos)"
 },
 {
  "docstring": "Remove an element from the queue.",
  "code": "def remove(self, elt):\n    try:\n        pos = self.position[elt]\n        del self.position[elt]\n    except KeyError:\n        raise\n    if pos == len(self.heap) - 1:\n        self.heap.pop()\n        return\n    last = self.heap.pop()\n    self.heap[pos] = last\n    self.position[last] = pos\n    self._siftup(pos)"
 },
 {
  "docstring": "Move smaller child up until hitting a leaf.\n\nBuilt to mimic code for heapq._siftup\nonly updating position dict too.",
  "code": "def _siftup(self, pos):\n    heap, position = (self.heap, self.position)\n    end_pos = len(heap)\n    startpos = pos\n    newitem = heap[pos]\n    child_pos = (pos << 1) + 1\n    while child_pos < end_pos:\n        child = heap[child_pos]\n        right_pos = child_pos + 1\n        if right_pos < end_pos:\n            right = heap[right_pos]\n            if not child < right:\n                child = right\n                child_pos = right_pos\n        heap[pos] = child\n        position[child] = pos\n        pos = child_pos\n        child_pos = (pos << 1) + 1\n    while pos > 0:\n        parent_pos = pos - 1 >> 1\n        parent = heap[parent_pos]\n        if not newitem < parent:\n            break\n        heap[pos] = parent\n        position[parent] = pos\n        pos = parent_pos\n    heap[pos] = newitem\n    position[newitem] = pos"
 },
 {
  "docstring": "Restore invariant. keep swapping with parent until smaller.\n\nBuilt to mimic code for heapq._siftdown\nonly updating position dict too.",
  "code": "def _siftdown(self, start_pos, pos):\n    heap, position = (self.heap, self.position)\n    newitem = heap[pos]\n    while pos > start_pos:\n        parent_pos = pos - 1 >> 1\n        parent = heap[parent_pos]\n        if not newitem < parent:\n            break\n        heap[pos] = parent\n        position[parent] = pos\n        pos = parent_pos\n    heap[pos] = newitem\n    position[newitem] = pos"
 },
 {
  "docstring": "Return flattened version of (possibly nested) iterable object.",
  "code": "def flatten(obj, result=None):\n    if not isinstance(obj, Iterable | Sized) or isinstance(obj, str):\n        return obj\n    if result is None:\n        result = []\n    for item in obj:\n        if not isinstance(item, Iterable | Sized) or isinstance(item, str):\n            result.append(item)\n        else:\n            flatten(item, result)\n    return tuple(result)"
 },
 {
  "docstring": "Return list of ints from sequence of integral numbers.\n\nAll elements of the sequence must satisfy int(element) == element\nor a ValueError is raised. Sequence is iterated through once.\n\nIf sequence is a list, the non-int values are replaced with ints.\nSo, no new list is created",
  "code": "def make_list_of_ints(sequence):\n    if not isinstance(sequence, list):\n        result = []\n        for i in sequence:\n            errmsg = f'sequence is not all integers: {i}'\n            try:\n                ii = int(i)\n            except ValueError:\n                raise nx.NetworkXError(errmsg) from None\n            if ii != i:\n                raise nx.NetworkXError(errmsg)\n            result.append(ii)\n        return result\n    for indx, i in enumerate(sequence):\n        errmsg = f'sequence is not all integers: {i}'\n        if isinstance(i, int):\n            continue\n        try:\n            ii = int(i)\n        except ValueError:\n            raise nx.NetworkXError(errmsg) from None\n        if ii != i:\n            raise nx.NetworkXError(errmsg)\n        sequence[indx] = ii\n    return sequence"
 },
 {
  "docstring": "Convert a dictionary of dictionaries to a numpy array\nwith optional mapping.",
  "code": "def dict_to_numpy_array(d, mapping=None):\n    try:\n        return _dict_to_numpy_array2(d, mapping)\n    except (AttributeError, TypeError):\n        return _dict_to_numpy_array1(d, mapping)"
 },
 {
  "docstring": "Convert a dictionary of dictionaries to a 2d numpy array\nwith optional mapping.",
  "code": "def _dict_to_numpy_array2(d, mapping=None):\n    import numpy as np\n    if mapping is None:\n        s = set(d.keys())\n        for k, v in d.items():\n            s.update(v.keys())\n        mapping = dict(zip(s, range(len(s))))\n    n = len(mapping)\n    a = np.zeros((n, n))\n    for k1, i in mapping.items():\n        for k2, j in mapping.items():\n            try:\n                a[i, j] = d[k1][k2]\n            except KeyError:\n                pass\n    return a"
 },
 {
  "docstring": "Convert a dictionary of numbers to a 1d numpy array with optional mapping.",
  "code": "def _dict_to_numpy_array1(d, mapping=None):\n    import numpy as np\n    if mapping is None:\n        s = set(d.keys())\n        mapping = dict(zip(s, range(len(s))))\n    n = len(mapping)\n    a = np.zeros(n)\n    for k1, i in mapping.items():\n        i = mapping[k1]\n        a[i] = d[k1]\n    return a"
 },
 {
  "docstring": "Returns an arbitrary element of `iterable` without removing it.\n\nThis is most useful for \"peeking\" at an arbitrary element of a set,\nbut can be used for any list, dictionary, etc., as well.\n\nParameters\n----------\niterable : `abc.collections.Iterable` instance\n    Any object that implements ``__iter__``, e.g. set, dict, list, tuple,\n    etc.\n\nReturns\n-------\nThe object that results from ``next(iter(iterable))``\n\nRaises\n------\nValueError\n    If `iterable` is an iterator (because the current implementation of\n    this function would consume an element from the iterator).\n\nExamples\n--------\nArbitrary elements from common Iterable objects:\n\n>>> nx.utils.arbitrary_element([1, 2, 3])  # list\n1\n>>> nx.utils.arbitrary_element((1, 2, 3))  # tuple\n1\n>>> nx.utils.arbitrary_element({1, 2, 3})  # set\n1\n>>> d = {k: v for k, v in zip([1, 2, 3], [3, 2, 1])}\n>>> nx.utils.arbitrary_element(d)  # dict_keys\n1\n>>> nx.utils.arbitrary_element(d.values())   # dict values\n3\n\n`str` is also an Iterable:\n\n>>> nx.utils.arbitrary_element(\"hello\")\n'h'\n\n:exc:`ValueError` is raised if `iterable` is an iterator:\n\n>>> iterator = iter([1, 2, 3])  # Iterator, *not* Iterable\n>>> nx.utils.arbitrary_element(iterator)\nTraceback (most recent call last):\n    ...\nValueError: cannot return an arbitrary item from an iterator\n\n",
  "code": "def arbitrary_element(iterable):\n    if isinstance(iterable, Iterator):\n        raise ValueError('cannot return an arbitrary item from an iterator')\n    return next(iter(iterable))"
 },
 {
  "docstring": "s -> (s0, s1), (s1, s2), (s2, s3), ...",
  "code": "def pairwise(iterable, cyclic=False):\n    a, b = tee(iterable)\n    first = next(b, None)\n    if cyclic is True:\n        return zip(a, chain(b, (first,)))\n    return zip(a, b)"
 },
 {
  "docstring": "Converts a many-to-one mapping into a one-to-many mapping.\n\n`many_to_one` must be a dictionary whose keys and values are all\n:term:`hashable`.\n\nThe return value is a dictionary mapping values from `many_to_one`\nto sets of keys from `many_to_one` that have that value.\n\nExamples\n--------\n>>> from networkx.utils import groups\n>>> many_to_one = {\"a\": 1, \"b\": 1, \"c\": 2, \"d\": 3, \"e\": 3}\n>>> groups(many_to_one)  # doctest: +SKIP\n{1: {'a', 'b'}, 2: {'c'}, 3: {'e', 'd'}}",
  "code": "def groups(many_to_one):\n    one_to_many = defaultdict(set)\n    for v, k in many_to_one.items():\n        one_to_many[k].add(v)\n    return dict(one_to_many)"
 },
 {
  "docstring": "Returns a numpy.random.RandomState or numpy.random.Generator instance\ndepending on input.\n\nParameters\n----------\nrandom_state : int or NumPy RandomState or Generator instance, optional (default=None)\n    If int, return a numpy.random.RandomState instance set with seed=int.\n    if `numpy.random.RandomState` instance, return it.\n    if `numpy.random.Generator` instance, return it.\n    if None or numpy.random, return the global random number generator used\n    by numpy.random.",
  "code": "def create_random_state(random_state=None):\n    import numpy as np\n    if random_state is None or random_state is np.random:\n        return np.random.mtrand._rand\n    if isinstance(random_state, np.random.RandomState):\n        return random_state\n    if isinstance(random_state, int):\n        return np.random.RandomState(random_state)\n    if isinstance(random_state, np.random.Generator):\n        return random_state\n    msg = f'{random_state} cannot be used to create a numpy.random.RandomState or\\nnumpy.random.Generator instance'\n    raise ValueError(msg)"
 },
 {
  "docstring": "Returns a random.Random instance depending on input.\n\nParameters\n----------\nrandom_state : int or random number generator or None (default=None)\n    If int, return a random.Random instance set with seed=int.\n    if random.Random instance, return it.\n    if None or the `random` package, return the global random number\n    generator used by `random`.\n    if np.random package, return the global numpy random number\n    generator wrapped in a PythonRandomInterface class.\n    if np.random.RandomState or np.random.Generator instance, return it\n    wrapped in PythonRandomInterface\n    if a PythonRandomInterface instance, return it",
  "code": "def create_py_random_state(random_state=None):\n    import random\n    try:\n        import numpy as np\n        if random_state is np.random:\n            return PythonRandomInterface(np.random.mtrand._rand)\n        if isinstance(random_state, np.random.RandomState | np.random.Generator):\n            return PythonRandomInterface(random_state)\n        if isinstance(random_state, PythonRandomInterface):\n            return random_state\n    except ImportError:\n        pass\n    if random_state is None or random_state is random:\n        return random._inst\n    if isinstance(random_state, random.Random):\n        return random_state\n    if isinstance(random_state, int):\n        return random.Random(random_state)\n    msg = f'{random_state} cannot be used to generate a random.Random instance'\n    raise ValueError(msg)"
 },
 {
  "docstring": "Check if nodes are equal.\n\nEquality here means equal as Python objects.\nNode data must match if included.\nThe order of nodes is not relevant.\n\nParameters\n----------\nnodes1, nodes2 : iterables of nodes, or (node, datadict) tuples\n\nReturns\n-------\nbool\n    True if nodes are equal, False otherwise.",
  "code": "def nodes_equal(nodes1, nodes2):\n    nlist1 = list(nodes1)\n    nlist2 = list(nodes2)\n    try:\n        d1 = dict(nlist1)\n        d2 = dict(nlist2)\n    except (ValueError, TypeError):\n        d1 = dict.fromkeys(nlist1)\n        d2 = dict.fromkeys(nlist2)\n    return d1 == d2"
 },
 {
  "docstring": "Check if edges are equal.\n\nEquality here means equal as Python objects.\nEdge data must match if included.\nThe order of the edges is not relevant.\n\nParameters\n----------\nedges1, edges2 : iterables of with u, v nodes as\n    edge tuples (u, v), or\n    edge tuples with data dicts (u, v, d), or\n    edge tuples with keys and data dicts (u, v, k, d)\n\nReturns\n-------\nbool\n    True if edges are equal, False otherwise.",
  "code": "def edges_equal(edges1, edges2):\n    from collections import defaultdict\n    d1 = defaultdict(dict)\n    d2 = defaultdict(dict)\n    c1 = 0\n    for c1, e in enumerate(edges1):\n        u, v = (e[0], e[1])\n        data = [e[2:]]\n        if v in d1[u]:\n            data = d1[u][v] + data\n        d1[u][v] = data\n        d1[v][u] = data\n    c2 = 0\n    for c2, e in enumerate(edges2):\n        u, v = (e[0], e[1])\n        data = [e[2:]]\n        if v in d2[u]:\n            data = d2[u][v] + data\n        d2[u][v] = data\n        d2[v][u] = data\n    if c1 != c2:\n        return False\n    for n, nbrdict in d1.items():\n        for nbr, datalist in nbrdict.items():\n            if n not in d2:\n                return False\n            if nbr not in d2[n]:\n                return False\n            d2datalist = d2[n][nbr]\n            for data in datalist:\n                if datalist.count(data) != d2datalist.count(data):\n                    return False\n    return True"
 },
 {
  "docstring": "Check if graphs are equal.\n\nEquality here means equal as Python objects (not isomorphism).\nNode, edge and graph data must match.\n\nParameters\n----------\ngraph1, graph2 : graph\n\nReturns\n-------\nbool\n    True if graphs are equal, False otherwise.",
  "code": "def graphs_equal(graph1, graph2):\n    return graph1.adj == graph2.adj and graph1.nodes == graph2.nodes and (graph1.graph == graph2.graph)"
 },
 {
  "docstring": "Return sample sequence of length n from a power law distribution.",
  "code": "@py_random_state(2)\ndef powerlaw_sequence(n, exponent=2.0, seed=None):\n    return [seed.paretovariate(exponent - 1) for i in range(n)]"
 },
 {
  "docstring": "Returns a random value chosen from the Zipf distribution.\n\nThe return value is an integer drawn from the probability distribution\n\n.. math::\n\n    p(x)=\\frac{x^{-\\alpha}}{\\zeta(\\alpha, x_{\\min})},\n\nwhere $\\zeta(\\alpha, x_{\\min})$ is the Hurwitz zeta function.\n\nParameters\n----------\nalpha : float\n  Exponent value of the distribution\nxmin : int\n  Minimum value\nseed : integer, random_state, or None (default)\n    Indicator of random number generation state.\n    See :ref:`Randomness<randomness>`.\n\nReturns\n-------\nx : int\n  Random value from Zipf distribution\n\nRaises\n------\nValueError:\n  If xmin < 1 or\n  If alpha <= 1\n\n",
  "code": "@py_random_state(2)\ndef zipf_rv(alpha, xmin=1, seed=None):\n    if xmin < 1:\n        raise ValueError('xmin < 1')\n    if alpha <= 1:\n        raise ValueError('a <= 1.0')\n    a1 = alpha - 1.0\n    b = 2 ** a1\n    while True:\n        u = 1.0 - seed.random()\n        v = seed.random()\n        x = int(xmin * u ** (-(1.0 / a1)))\n        t = (1.0 + 1.0 / x) ** a1\n        if v * x * (t - 1.0) / (b - 1.0) <= t / b:\n            break\n    return x"
 },
 {
  "docstring": "Returns normalized cumulative distribution from discrete distribution.",
  "code": "def cumulative_distribution(distribution):\n    cdf = [0.0]\n    psum = sum(distribution)\n    for i in range(len(distribution)):\n        cdf.append(cdf[i] + distribution[i] / psum)\n    return cdf"
 },
 {
  "docstring": "Return sample sequence of length n from a given discrete distribution\nor discrete cumulative distribution.\n\nOne of the following must be specified.\n\ndistribution = histogram of values, will be normalized\n\ncdistribution = normalized discrete cumulative distribution",
  "code": "@py_random_state(3)\ndef discrete_sequence(n, distribution=None, cdistribution=None, seed=None):\n    import bisect\n    if cdistribution is not None:\n        cdf = cdistribution\n    elif distribution is not None:\n        cdf = cumulative_distribution(distribution)\n    else:\n        raise nx.NetworkXError('discrete_sequence: distribution or cdistribution missing')\n    inputseq = [seed.random() for i in range(n)]\n    seq = [bisect.bisect_left(cdf, s) - 1 for s in inputseq]\n    return seq"
 },
 {
  "docstring": "Returns k items without replacement from a weighted sample.\n\nThe input is a dictionary of items with weights as values.",
  "code": "@py_random_state(2)\ndef random_weighted_sample(mapping, k, seed=None):\n    if k > len(mapping):\n        raise ValueError('sample larger than population')\n    sample = set()\n    while len(sample) < k:\n        sample.add(weighted_choice(mapping, seed))\n    return list(sample)"
 },
 {
  "docstring": "Returns a single element from a weighted sample.\n\nThe input is a dictionary of items with weights as values.",
  "code": "@py_random_state(1)\ndef weighted_choice(mapping, seed=None):\n    rnd = seed.random() * sum(mapping.values())\n    for k, w in mapping.items():\n        rnd -= w\n        if rnd < 0:\n            return k"
 },
 {
  "docstring": "Generate an ordering (permutation) of the graph nodes to make\na sparse matrix.\n\nUses the Cuthill-McKee heuristic (based on breadth-first search) [1]_.\n\nParameters\n----------\nG : graph\n  A NetworkX graph\n\nheuristic : function, optional\n  Function to choose starting node for RCM algorithm.  If None\n  a node from a pseudo-peripheral pair is used.  A user-defined function\n  can be supplied that takes a graph object and returns a single node.\n\nReturns\n-------\nnodes : generator\n   Generator of nodes in Cuthill-McKee ordering.\n\nExamples\n--------\n>>> from networkx.utils import cuthill_mckee_ordering\n>>> G = nx.path_graph(4)\n>>> rcm = list(cuthill_mckee_ordering(G))\n>>> A = nx.adjacency_matrix(G, nodelist=rcm)\n\nSmallest degree node as heuristic function:\n\n>>> def smallest_degree(G):\n...     return min(G, key=G.degree)\n>>> rcm = list(cuthill_mckee_ordering(G, heuristic=smallest_degree))\n\n\nSee Also\n--------\nreverse_cuthill_mckee_ordering\n\n",
  "code": "def cuthill_mckee_ordering(G, heuristic=None):\n    for c in nx.connected_components(G):\n        yield from connected_cuthill_mckee_ordering(G.subgraph(c), heuristic)"
 },
 {
  "docstring": "Generate an ordering (permutation) of the graph nodes to make\na sparse matrix.\n\nUses the reverse Cuthill-McKee heuristic (based on breadth-first search)\n[1]_.\n\nParameters\n----------\nG : graph\n  A NetworkX graph\n\nheuristic : function, optional\n  Function to choose starting node for RCM algorithm.  If None\n  a node from a pseudo-peripheral pair is used.  A user-defined function\n  can be supplied that takes a graph object and returns a single node.\n\nReturns\n-------\nnodes : generator\n   Generator of nodes in reverse Cuthill-McKee ordering.\n\nExamples\n--------\n>>> from networkx.utils import reverse_cuthill_mckee_ordering\n>>> G = nx.path_graph(4)\n>>> rcm = list(reverse_cuthill_mckee_ordering(G))\n>>> A = nx.adjacency_matrix(G, nodelist=rcm)\n\nSmallest degree node as heuristic function:\n\n>>> def smallest_degree(G):\n...     return min(G, key=G.degree)\n>>> rcm = list(reverse_cuthill_mckee_ordering(G, heuristic=smallest_degree))\n\n\nSee Also\n--------\ncuthill_mckee_ordering\n\n",
  "code": "def reverse_cuthill_mckee_ordering(G, heuristic=None):\n    return reversed(list(cuthill_mckee_ordering(G, heuristic=heuristic)))"
 },
 {
  "docstring": "Create a new empty union-find structure.\n\nIf *elements* is an iterable, this structure will be initialized\nwith the discrete partition on the given set of elements.",
  "code": "def __init__(self, elements=None):\n    if elements is None:\n        elements = ()\n    self.parents = {}\n    self.weights = {}\n    for x in elements:\n        self.weights[x] = 1\n        self.parents[x] = x"
 },
 {
  "docstring": "Find and return the name of the set containing the object.",
  "code": "def __getitem__(self, object):\n    if object not in self.parents:\n        self.parents[object] = object\n        self.weights[object] = 1\n        return object\n    path = []\n    root = self.parents[object]\n    while root != object:\n        path.append(object)\n        object = root\n        root = self.parents[object]\n    for ancestor in path:\n        self.parents[ancestor] = root\n    return root"
 },
 {
  "docstring": "Iterate through all items ever found or unioned by this structure.",
  "code": "def __iter__(self):\n    return iter(self.parents)"
 },
 {
  "docstring": "Iterates over the sets stored in this structure.\n\nFor example::\n\n    >>> partition = UnionFind(\"xyz\")\n    >>> sorted(map(sorted, partition.to_sets()))\n    [['x'], ['y'], ['z']]\n    >>> partition.union(\"x\", \"y\")\n    >>> sorted(map(sorted, partition.to_sets()))\n    [['x', 'y'], ['z']]",
  "code": "def to_sets(self):\n    for x in self.parents:\n        _ = self[x]\n    yield from groups(self.parents).values()"
 },
 {
  "docstring": "Find the sets containing the objects and merge them all.",
  "code": "def union(self, *objects):\n    roots = iter(sorted({self[x] for x in objects}, key=lambda r: self.weights[r], reverse=True))\n    try:\n        root = next(roots)\n    except StopIteration:\n        return\n    for r in roots:\n        self.weights[root] += self.weights[r]\n        self.parents[r] = root"
 },
 {
  "docstring": "Bad because it doesn't wrap the f signature (clobbers it)",
  "code": "def add_one_to_first_bad_decorator(f):\n\n    def decorated(a, *args, **kwargs):\n        return f(a + 1, *args, **kwargs)\n    return decorated"
 },
 {
  "docstring": "Value error is raised when input is an iterator.",
  "code": "@pytest.mark.parametrize('iterator', ((i for i in range(3)), iter([1, 2, 3])))\ndef test_arbitrary_element_raises(iterator):\n    with pytest.raises(ValueError, match='from an iterator'):\n        arbitrary_element(iterator)"
 },
 {
  "docstring": "Ensure objects are not unintentionally exposed in utils namespace.",
  "code": "def test_utils_namespace():\n    with pytest.raises(ImportError):\n        from networkx.utils import nx\n    with pytest.raises(ImportError):\n        from networkx.utils import sys\n    with pytest.raises(ImportError):\n        from networkx.utils import defaultdict, deque"
 }
]